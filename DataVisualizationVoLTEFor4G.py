import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import numpy as np
import os
import warnings
from datetime import datetime, timedelta
from PIL import Image, ImageDraw, ImageFont
import math

# T·∫Øt warnings ƒë·ªÉ output s·∫°ch h∆°n
warnings.filterwarnings('ignore')


class VoLTEKPIProcessor:
    def __init__(self):
        """
        Kh·ªüi t·∫°o class processor v·ªõi c·∫•u h√¨nh matplotlib ti·∫øng Vi·ªát
        """
        # C·∫•u h√¨nh matplotlib ƒë·ªÉ hi·ªÉn th·ªã ti·∫øng Vi·ªát
        plt.rcParams['font.family'] = 'DejaVu Sans'
        plt.rcParams['axes.unicode_minus'] = False

        self.cleaned_data = {}
        self.csv_files = {}

        # ƒê·ªãnh nghƒ©a c√°c bi·ªÉu ƒë·ªì c·ª• th·ªÉ c·∫ßn t·∫°o
        self.required_charts = {
            'hourly': [
                {
                    'type': 'line',
                    'y_col': 'VoLTE Traffic (Erl)',
                    'title': 'VoLTE Traffic (Erl) by Date and Hour'
                },
                {
                    'type': 'combo',
                    'y_line': 'SRVCC HOSR UTRAN',
                    'y_bar': 'SRVCC HO Att UTRAN',
                    'title': 'SRVCC HOSR UTRAN and SRVCC HO Att UTRAN by Date and Hour'
                },
                {
                    'type': 'combo',
                    'y_line': 'VoLTE CSSR QCI1',
                    'y_bar': 'VoLTE RAB Att QCI1',
                    'title': 'VoLTE CSSR QCI1 and VoLTE RAB Att QCI1 by Date and Hour'
                },
                {
                    'type': 'combo',
                    'y_line': 'VoLTE CSSR QCI5',
                    'y_bar': 'VoLTE RAB Att QCI5',
                    'title': 'VoLTE CSSR QCI5 and VoLTE RAB Att QCI5 by Date and Hour'
                },
                {
                    'type': 'combo',
                    'y_line': 'VoLTE CDR QCI1',
                    'y_bar': 'VoLTE Call Drop QCI1',
                    'title': 'VoLTE CDR QCI1 and VoLTE Call Drop QCI1 by Date and Hour'
                },
                {
                    'type': 'combo',
                    'y_line': 'VoLTE CDR QCI5',
                    'y_bar': 'VoLTE Call Drop QCI5',
                    'title': 'VoLTE CDR QCI5 and VoLTE Call Drop QCI5 by Date and Hour'
                },
                {
                    'type': 'combo',
                    'y_line': 'VOLTE UL Packet Loss',
                    'y_bar': 'VOLTE UL Packet Loss_Mau so',
                    'title': 'VOLTE UL Packet Loss and VOLTE UL Packet Loss_Mau so by Date and Hour'
                },
                {
                    'type': 'combo',
                    'y_line': 'VOLTE DL Packet Loss',
                    'y_bar': 'VOLTE DL Packet Loss_Mau so',
                    'title': 'VOLTE DL Packet Loss and VOLTE DL Packet Loss_Mau so by Date and Hour'
                }
            ],
            'daily': [
                {
                    'type': 'line',
                    'y_col': 'VoLTE Traffic (Erl)',
                    'title': 'VoLTE Traffic (Erl) by Date'
                },
                {
                    'type': 'combo',
                    'y_line': 'SRVCC HOSR UTRAN',
                    'y_bar': 'SRVCC HO Att UTRAN',
                    'title': 'SRVCC HOSR UTRAN and SRVCC HO Att UTRAN by Date'
                },
                {
                    'type': 'combo',
                    'y_line': 'VoLTE CSSR QCI1',
                    'y_bar': 'VoLTE RAB Att QCI1',
                    'title': 'VoLTE CSSR QCI1 and VoLTE RAB Att QCI1 by Date'
                },
                {
                    'type': 'combo',
                    'y_line': 'VoLTE CSSR QCI5',
                    'y_bar': 'VoLTE RAB Att QCI5',
                    'title': 'VoLTE CSSR QCI5 and VoLTE RAB Att QCI5 by Date'
                },
                {
                    'type': 'combo',
                    'y_line': 'VoLTE CDR QCI1',
                    'y_bar': 'VoLTE Call Drop QCI1',
                    'title': 'VoLTE CDR QCI1 and VoLTE Call Drop QCI1 by Date'
                },
                {
                    'type': 'combo',
                    'y_line': 'VoLTE CDR QCI5',
                    'y_bar': 'VoLTE Call Drop QCI5',
                    'title': 'VoLTE CDR QCI5 and VoLTE Call Drop QCI5 by Date'
                },
                {
                    'type': 'combo',
                    'y_line': 'pmErabRelAbnormalEnbActHprQci',
                    'y_bar': 'VoLTE Call Drop QCI1',
                    'title': 'pmErabRelAbnormalEnbActHprQci and VoLTE Call Drop QCI1 by Date'
                }
            ]
        }

        print("VOLTE KPI DATA PROCESSOR - ENHANCED VERSION WITH FIXED HOURLY CHARTS")
        print("=" * 70)

    def read_excel_file(self, excel_path):
        """
        ƒê·ªçc file Excel v√† x√°c ƒë·ªãnh c√°c sheets c·∫ßn x·ª≠ l√Ω
        """
        try:
            print(f"üìñ ƒêang ƒë·ªçc file Excel: {excel_path}")

            # ƒê·ªçc t·∫•t c·∫£ sheet names
            excel_file = pd.ExcelFile(excel_path)
            all_sheets = excel_file.sheet_names
            print(f"üìä T·∫•t c·∫£ sheets: {all_sheets}")

            # X√°c ƒë·ªãnh c√°c sheet d·ªØ li·ªáu c·∫ßn x·ª≠ l√Ω (ch·ªâ 2 sheet ƒë·∫ßu ti√™n)
            target_sheets = ["Net KPI_Daily", "Net KPI_Hourly"]

            # T√¨m sheets c√≥ s·∫µn
            available_sheets = []
            for sheet in target_sheets:
                if sheet in all_sheets:
                    available_sheets.append(sheet)
                    print(f"‚úÖ T√¨m th·∫•y sheet: {sheet}")
                else:
                    # T√¨m sheet t∆∞∆°ng t·ª±
                    similar_sheet = self._find_similar_sheet(sheet, all_sheets)
                    if similar_sheet:
                        available_sheets.append(similar_sheet)
                        print(f"‚úÖ T√¨m th·∫•y sheet t∆∞∆°ng t·ª±: {similar_sheet}")
                    else:
                        print(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y sheet: {sheet}")

            if not available_sheets:
                print("‚ùå Kh√¥ng t√¨m th·∫•y sheet d·ªØ li·ªáu c·∫ßn thi·∫øt!")
                return None

            # ƒê·ªçc d·ªØ li·ªáu t·ª´ c√°c sheets
            dataframes = {}
            for sheet_name in available_sheets:
                print(f"üìñ ƒêang ƒë·ªçc sheet: {sheet_name}")

                # ƒê·ªçc v·ªõi nhi·ªÅu ph∆∞∆°ng ph√°p ƒë·ªÉ tr√°nh l·ªói
                df = self._read_sheet_robust(excel_file, sheet_name)

                if df is not None and not df.empty:
                    dataframes[sheet_name] = df
                    print(f"   üìä K√≠ch th∆∞·ªõc raw: {df.shape}")
                else:
                    print(f"   ‚ùå Kh√¥ng th·ªÉ ƒë·ªçc d·ªØ li·ªáu t·ª´ {sheet_name}")

            return dataframes

        except Exception as e:
            print(f"‚ùå L·ªói khi ƒë·ªçc file Excel: {e}")
            return None

    def _find_similar_sheet(self, target_sheet, all_sheets):
        """
        T√¨m sheet c√≥ t√™n t∆∞∆°ng t·ª±
        """
        target_lower = target_sheet.lower()
        for sheet in all_sheets:
            sheet_lower = sheet.lower()
            if any(keyword in sheet_lower for keyword in ['daily', 'hourly', 'kpi']):
                if 'daily' in target_lower and 'daily' in sheet_lower:
                    return sheet
                elif 'hourly' in target_lower and ('hourly' in sheet_lower or 'hour' in sheet_lower):
                    return sheet
        return None

    def _read_sheet_robust(self, excel_file, sheet_name):
        """
        ƒê·ªçc sheet v·ªõi nhi·ªÅu ph∆∞∆°ng ph√°p ƒë·ªÉ ƒë·∫£m b·∫£o th√†nh c√¥ng
        """
        try:
            # Th·ª≠ ƒë·ªçc v·ªõi header m·∫∑c ƒë·ªãnh
            df = pd.read_excel(excel_file, sheet_name=sheet_name, header=0)

            # Ki·ªÉm tra xem c√≥ ph·∫£i header th·ª±c s·ª± kh√¥ng
            if self._is_valid_header(df):
                return df

            # N·∫øu kh√¥ng, th·ª≠ t√¨m header th·ª±c s·ª±
            for header_row in range(0, min(10, len(df))):
                try:
                    df_test = pd.read_excel(excel_file, sheet_name=sheet_name, header=header_row)
                    if self._is_valid_header(df_test):
                        print(f"   üéØ T√¨m th·∫•y header th·ª±c t·∫ø ·ªü d√≤ng {header_row}")
                        return df_test
                except:
                    continue

            # N·∫øu v·∫´n kh√¥ng t√¨m ƒë∆∞·ª£c, s·ª≠ d·ª•ng ph∆∞∆°ng ph√°p cu·ªëi c√πng
            df = pd.read_excel(excel_file, sheet_name=sheet_name, header=None)
            return df

        except Exception as e:
            print(f"   ‚ùå L·ªói khi ƒë·ªçc sheet {sheet_name}: {e}")
            return None

    def _is_valid_header(self, df):
        """
        Ki·ªÉm tra xem header c√≥ h·ª£p l·ªá kh√¥ng
        """
        if df.empty or len(df.columns) < 2:
            return False

        # T√¨m c√°c t·ª´ kh√≥a quan tr·ªçng trong header
        header_keywords = ['Date', 'Time', 'VoLTE', 'CSSR', 'CDR', 'Traffic',
                           'SRVCC', 'SR', 'HOSR', 'GB', '%', 'Rate', 'QCI', 'Att', 'Drop']

        header_str = ' '.join([str(col) for col in df.columns])

        # Ki·ªÉm tra c√≥ √≠t nh·∫•t 2 t·ª´ kh√≥a
        keyword_count = sum(1 for keyword in header_keywords if keyword in header_str)

        return keyword_count >= 2

    def clean_dataframe_enhanced(self, df, sheet_name):
        """
        L√†m s·∫°ch dataframe v·ªõi x·ª≠ l√Ω n√¢ng cao v√† chi ti·∫øt h∆°n
        """
        print(f"üßπ L√†m s·∫°ch d·ªØ li·ªáu n√¢ng cao cho {sheet_name}...")
        print(f"   üìä Tr∆∞·ªõc khi l√†m s·∫°ch: {df.shape}")

        if df.empty:
            print("   ‚ùå DataFrame r·ªóng!")
            return None

        # 1. X·ª≠ l√Ω t√™n c·ªôt
        df = self._clean_column_names(df)

        # 2. T√¨m v√† thi·∫øt l·∫≠p header ƒë√∫ng
        df = self._fix_header_row(df, sheet_name)

        if df is None or df.empty:
            return None

        # 3. X√≥a c√°c c·ªôt v√† h√†ng kh√¥ng c·∫ßn thi·∫øt
        df = self._remove_unnecessary_data(df)

        # 4. X·ª≠ l√Ω c·ªôt Date/Time
        df = self._process_datetime_column(df, sheet_name)

        # 5. Chuy·ªÉn ƒë·ªïi c√°c c·ªôt s·ªë
        df = self._convert_numeric_columns(df)

        # 6. L√†m s·∫°ch d·ªØ li·ªáu cu·ªëi c√πng
        df = self._final_cleanup(df)

        if df is None or df.empty:
            print(f"   ‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu h·ª£p l·ªá sau khi l√†m s·∫°ch!")
            return None

        print(f"   ‚ú® Sau khi l√†m s·∫°ch: {df.shape}")
        print(f"   üìã C√°c c·ªôt cu·ªëi c√πng: {list(df.columns[:10])}")

        return df

    def _clean_column_names(self, df):
        """
        L√†m s·∫°ch t√™n c·ªôt
        """
        df.columns = df.columns.astype(str)
        df.columns = [col.strip().replace('\n', ' ').replace('\r', ' ').replace('  ', ' ')
                      for col in df.columns]
        return df

    def _fix_header_row(self, df, sheet_name):
        """
        T√¨m v√† s·ª≠a d√≤ng header ƒë√∫ng
        """
        # T√¨m d√≤ng ch·ª©a t·ª´ kh√≥a quan tr·ªçng
        header_keywords = ['Date', 'Time', 'VoLTE', 'CSSR', 'CDR', 'Traffic', 'SRVCC', 'QCI', 'Att', 'Drop']

        for i in range(min(5, len(df))):
            row_str = ' '.join([str(val) for val in df.iloc[i].values if pd.notna(val)])
            keyword_count = sum(1 for keyword in header_keywords if keyword in row_str)

            if keyword_count >= 2:  # √çt nh·∫•t 2 t·ª´ kh√≥a
                print(f"   üéØ T√¨m th·∫•y header th·ª±c t·∫ø ·ªü d√≤ng {i}")

                # T·∫°o header m·ªõi
                new_header = []
                for val in df.iloc[i].values:
                    if pd.notna(val) and str(val).strip() != '':
                        new_header.append(str(val).strip())
                    else:
                        new_header.append(f'Col_{len(new_header)}')

                # T·∫°o DataFrame m·ªõi
                data_rows = df.iloc[i + 1:].values
                if len(data_rows) == 0:
                    return None

                # ƒê·∫£m b·∫£o s·ªë c·ªôt kh·ªõp
                min_cols = min(len(new_header), data_rows.shape[1] if len(data_rows) > 0 else 0)
                if min_cols == 0:
                    return None

                new_header = new_header[:min_cols]
                data_rows = data_rows[:, :min_cols]

                df_new = pd.DataFrame(data_rows, columns=new_header)
                return df_new

        return df  # Tr·∫£ v·ªÅ DataFrame g·ªëc n·∫øu kh√¥ng t√¨m th·∫•y header t·ªët h∆°n

    def _remove_unnecessary_data(self, df):
        """
        X√≥a c√°c c·ªôt v√† h√†ng kh√¥ng c·∫ßn thi·∫øt
        """
        # X√≥a c√°c c·ªôt Unnamed
        unnamed_cols = [col for col in df.columns if 'Unnamed' in str(col) or 'Col_' in str(col)]
        if unnamed_cols:
            df = df.drop(columns=unnamed_cols, errors='ignore')
            print(f"   üóëÔ∏è ƒê√£ x√≥a {len(unnamed_cols)} c·ªôt kh√¥ng t√™n")

        # X√≥a c√°c c·ªôt ho√†n to√†n tr·ªëng
        df = df.dropna(axis=1, how='all')

        # X√≥a c√°c h√†ng ho√†n to√†n tr·ªëng
        df = df.dropna(axis=0, how='all')

        # X√≥a c√°c h√†ng c√≥ qu√° √≠t d·ªØ li·ªáu
        threshold = max(2, len(df.columns) * 0.3)  # √çt nh·∫•t 30% c·ªôt c√≥ d·ªØ li·ªáu
        df = df.dropna(thresh=threshold)

        return df.reset_index(drop=True)

    def _process_datetime_column(self, df, sheet_name):
        """
        X·ª≠ l√Ω c·ªôt Date/Time v·ªõi ƒë·∫∑c bi·ªát cho d·ªØ li·ªáu Hourly
        """
        if len(df.columns) == 0 or len(df) == 0:
            return df

        # T√¨m c·ªôt Date
        date_col = None
        for col in df.columns[:3]:  # Ki·ªÉm tra 3 c·ªôt ƒë·∫ßu
            col_str = str(col).lower()
            if any(keyword in col_str for keyword in ['date', 'time', 'ng√†y', 'gi·ªù']):
                date_col = col
                break

        if date_col is None:
            date_col = df.columns[0]  # M·∫∑c ƒë·ªãnh c·ªôt ƒë·∫ßu ti√™n

        print(f"   üìÖ X·ª≠ l√Ω c·ªôt th·ªùi gian: {date_col}")

        try:
            # X·ª≠ l√Ω ƒë·∫∑c bi·ªát cho d·ªØ li·ªáu Hourly
            if 'hourly' in sheet_name.lower() or 'hour' in sheet_name.lower():
                df = self._process_hourly_datetime(df, date_col)
            else:
                # X·ª≠ l√Ω b√¨nh th∆∞·ªùng cho Daily
                original_data = df[date_col].copy()
                df[date_col] = pd.to_datetime(df[date_col], errors='coerce')

                # N·∫øu c√≥ qu√° nhi·ªÅu NaT, th·ª≠ ph∆∞∆°ng ph√°p kh√°c
                nat_count = df[date_col].isna().sum()
                if nat_count > len(df) * 0.5:  # H∆°n 50% l√† NaT
                    try:
                        df[date_col] = pd.to_datetime(original_data, origin='1899-12-30', unit='D', errors='coerce')
                    except:
                        df[date_col] = pd.to_datetime(original_data, infer_datetime_format=True, errors='coerce')

            # Lo·∫°i b·ªè c√°c h√†ng c√≥ ng√†y kh√¥ng h·ª£p l·ªá
            valid_dates = df[date_col].notna()
            df = df[valid_dates].reset_index(drop=True)

            # S·∫Øp x·∫øp theo ng√†y
            if len(df) > 0:
                df = df.sort_values(by=date_col).reset_index(drop=True)
                print(f"   ‚úÖ ƒê√£ chuy·ªÉn ƒë·ªïi {len(df)} ng√†y h·ª£p l·ªá")

        except Exception as e:
            print(f"   ‚ö†Ô∏è L·ªói x·ª≠ l√Ω ng√†y th√°ng: {e}")

        return df

    def _process_hourly_datetime(self, df, date_col):
        """
        X·ª≠ l√Ω ƒë·∫∑c bi·ªát cho d·ªØ li·ªáu hourly ƒë·ªÉ t·∫°o datetime ch√≠nh x√°c
        """
        print("   üïê X·ª≠ l√Ω d·ªØ li·ªáu hourly v·ªõi datetime ƒë·∫ßy ƒë·ªß...")

        # Ki·ªÉm tra xem c√≥ c·ªôt Hour ri√™ng bi·ªát kh√¥ng
        hour_col = None
        for col in df.columns:
            if 'hour' in str(col).lower() or 'time' in str(col).lower():
                if col != date_col:
                    hour_col = col
                    break

        if hour_col is not None:
            print(f"   üïê T√¨m th·∫•y c·ªôt gi·ªù ri√™ng bi·ªát: {hour_col}")
            # K·∫øt h·ª£p Date v√† Hour th√†nh datetime ƒë·∫ßy ƒë·ªß
            try:
                df[date_col] = pd.to_datetime(df[date_col], errors='coerce')
                df[hour_col] = pd.to_numeric(df[hour_col], errors='coerce')

                # T·∫°o datetime ƒë·∫ßy ƒë·ªß
                df['datetime_full'] = df.apply(lambda row:
                                               row[date_col] + pd.Timedelta(hours=row[hour_col])
                                               if pd.notna(row[date_col]) and pd.notna(row[hour_col])
                                               else pd.NaT, axis=1)

                # Thay th·∫ø c·ªôt date b·∫±ng datetime ƒë·∫ßy ƒë·ªß
                df[date_col] = df['datetime_full']
                df = df.drop(['datetime_full'], axis=1, errors='ignore')

                # X√≥a c·ªôt hour n·∫øu kh√¥ng c·∫ßn thi·∫øt cho chart
                if hour_col not in [col for chart in self.required_charts.get('hourly', [])
                                    for col in [chart.get('y_col'), chart.get('y_line'), chart.get('y_bar')] if col]:
                    df = df.drop([hour_col], axis=1, errors='ignore')

            except Exception as e:
                print(f"   ‚ö†Ô∏è L·ªói k·∫øt h·ª£p Date-Hour: {e}")
                # Fall back v·ªÅ x·ª≠ l√Ω th√¥ng th∆∞·ªùng
                df[date_col] = pd.to_datetime(df[date_col], errors='coerce')
        else:
            # Th·ª≠ ph√¢n t√≠ch datetime t·ª´ c·ªôt duy nh·∫•t
            original_data = df[date_col].copy()

            # Th·ª≠ c√°c format kh√°c nhau cho hourly data
            formats_to_try = [
                '%Y-%m-%d %H:%M:%S',
                '%Y-%m-%d %H:%M',
                '%m/%d/%Y %H:%M',
                '%d/%m/%Y %H:%M',
                '%Y-%m-%d %H',
                None  # Let pandas infer
            ]

            for fmt in formats_to_try:
                try:
                    if fmt is None:
                        df[date_col] = pd.to_datetime(original_data, errors='coerce', infer_datetime_format=True)
                    else:
                        df[date_col] = pd.to_datetime(original_data, format=fmt, errors='coerce')

                    # Ki·ªÉm tra th√†nh c√¥ng
                    valid_count = df[date_col].notna().sum()
                    if valid_count > len(df) * 0.7:  # √çt nh·∫•t 70% th√†nh c√¥ng
                        print(f"   ‚úÖ Th√†nh c√¥ng v·ªõi format: {fmt if fmt else 'auto-detect'}")
                        break
                except:
                    continue

            # N·∫øu v·∫´n kh√¥ng th√†nh c√¥ng, th·ª≠ x·ª≠ l√Ω s·ªë Excel
            if df[date_col].notna().sum() < len(df) * 0.5:
                try:
                    df[date_col] = pd.to_datetime(original_data, origin='1899-12-30', unit='D', errors='coerce')
                    print("   ‚úÖ ƒê√£ s·ª≠ d·ª•ng origin Excel ƒë·ªÉ convert")
                except:
                    print("   ‚ö†Ô∏è Kh√¥ng th·ªÉ convert datetime, gi·ªØ nguy√™n d·ªØ li·ªáu g·ªëc")

        return df

    def _convert_numeric_columns(self, df):
        """
        Chuy·ªÉn ƒë·ªïi c√°c c·ªôt s·ªë
        """
        numeric_converted = 0

        # B·ªè qua c·ªôt ƒë·∫ßu ti√™n (Date/Time)
        for col in df.columns[1:]:
            try:
                original_count = df[col].count()

                # X·ª≠ l√Ω c√°c k√Ω t·ª± ƒë·∫∑c bi·ªát trong s·ªë
                if df[col].dtype == 'object':
                    df[col] = df[col].astype(str).str.replace(',', '').str.replace('%', '').str.replace(' ', '')
                    df[col] = df[col].replace(['', 'nan', 'NaN', 'null', 'NULL', '-'], np.nan)

                # Chuy·ªÉn ƒë·ªïi sang s·ªë
                df[col] = pd.to_numeric(df[col], errors='coerce')

                new_count = df[col].count()

                if new_count > 0:
                    numeric_converted += 1
                    if new_count < original_count:
                        lost_pct = (original_count - new_count) / original_count * 100
                        if lost_pct > 20:  # C·∫£nh b√°o n·∫øu m·∫•t qu√° 20% d·ªØ li·ªáu
                            print(f"   ‚ö†Ô∏è {col}: m·∫•t {lost_pct:.1f}% d·ªØ li·ªáu ({original_count} -> {new_count})")

            except Exception as e:
                print(f"   ‚ö†Ô∏è L·ªói chuy·ªÉn ƒë·ªïi c·ªôt {col}: {e}")
                continue

        print(f"   üî¢ ƒê√£ chuy·ªÉn ƒë·ªïi {numeric_converted} c·ªôt sang ki·ªÉu s·ªë")
        return df

    def _final_cleanup(self, df):
        """
        L√†m s·∫°ch cu·ªëi c√πng
        """
        # X√≥a c√°c h√†ng c√≥ qu√° √≠t d·ªØ li·ªáu
        min_valid_cols = max(2, len(df.columns) * 0.4)  # √çt nh·∫•t 40% c·ªôt c√≥ d·ªØ li·ªáu
        df = df.dropna(thresh=min_valid_cols)

        # X√≥a c√°c c·ªôt c√≥ qu√° √≠t d·ªØ li·ªáu
        min_valid_rows = max(1, len(df) * 0.1)  # √çt nh·∫•t 10% h√†ng c√≥ d·ªØ li·ªáu
        df = df.dropna(axis=1, thresh=min_valid_rows)

        return df.reset_index(drop=True)

    def save_to_csv(self, dataframes, output_dir="output_charts"):
        """
        L∆∞u c√°c DataFrame th√†nh file CSV
        """
        print(f"\nüíæ L∆∞u d·ªØ li·ªáu th√†nh CSV...")
        os.makedirs(output_dir, exist_ok=True)

        csv_files = {}

        for sheet_name, df in dataframes.items():
            # T·∫°o t√™n file CSV
            if 'Daily' in sheet_name or 'daily' in sheet_name.lower():
                csv_filename = 'Net_KPI_Daily.csv'
            elif 'Hourly' in sheet_name or 'hourly' in sheet_name.lower() or 'hour' in sheet_name.lower():
                csv_filename = 'Net_KPI_Hourly.csv'
            else:
                safe_name = "".join(c for c in sheet_name if c.isalnum() or c in (' ', '-', '_')).replace(' ', '_')
                csv_filename = f'{safe_name}.csv'

            csv_path = os.path.join(output_dir, csv_filename)

            try:
                df.to_csv(csv_path, index=False, encoding='utf-8-sig')
                print(f"‚úÖ ƒê√£ l∆∞u: {csv_filename} ({df.shape[0]} h√†ng √ó {df.shape[1]} c·ªôt)")

                # L∆∞u th√¥ng tin ƒë·ªÉ t·∫°o bi·ªÉu ƒë·ªì sau
                csv_files[sheet_name] = csv_path
                self.cleaned_data[sheet_name] = df

            except Exception as e:
                print(f"‚ùå L·ªói khi l∆∞u {csv_filename}: {e}")

        self.csv_files = csv_files
        return csv_files

    def _find_matching_column(self, df, target_cols):
        """
        T√¨m c·ªôt ph√π h·ª£p nh·∫•t t·ª´ danh s√°ch t√™n c·ªôt m·ª•c ti√™u
        """
        if isinstance(target_cols, str):
            target_cols = [target_cols]

        df_columns_lower = {col.lower(): col for col in df.columns}

        for target in target_cols:
            target_lower = target.lower()
            # T√¨m kh·ªõp ch√≠nh x√°c
            if target_lower in df_columns_lower:
                return df_columns_lower[target_lower]

            # T√¨m kh·ªõp m·ªôt ph·∫ßn
            for col_lower, col_original in df_columns_lower.items():
                if target_lower in col_lower or any(word in col_lower for word in target_lower.split()):
                    return col_original

        return None

    def create_specific_charts(self, output_dir="output_charts"):
        """
        T·∫°o c√°c bi·ªÉu ƒë·ªì c·ª• th·ªÉ theo y√™u c·∫ßu v·ªõi c·∫£i thi·ªán cho Hourly
        """
        print(f"\nüé® T·∫°o c√°c bi·ªÉu ƒë·ªì c·ª• th·ªÉ theo y√™u c·∫ßu...")

        created_charts = []

        for sheet_name, df in self.cleaned_data.items():
            print(f"\nüìä X·ª≠ l√Ω d·ªØ li·ªáu t·ª´ {sheet_name}...")

            # X√°c ƒë·ªãnh lo·∫°i d·ªØ li·ªáu (daily ho·∫∑c hourly)
            data_type = 'daily' if 'daily' in sheet_name.lower() else 'hourly'

            # T·∫°o th∆∞ m·ª•c cho bi·ªÉu ƒë·ªì
            chart_folder = os.path.join(output_dir, f"Chart_{data_type}")
            os.makedirs(chart_folder, exist_ok=True)

            # L·∫•y danh s√°ch bi·ªÉu ƒë·ªì c·∫ßn t·∫°o
            charts_config = self.required_charts.get(data_type, [])

            if not charts_config:
                print(f"   ‚ö†Ô∏è Kh√¥ng c√≥ c·∫•u h√¨nh bi·ªÉu ƒë·ªì cho {data_type}")
                continue

            # T√¨m c·ªôt th·ªùi gian
            time_col = df.columns[0]  # Gi·∫£ ƒë·ªãnh c·ªôt ƒë·∫ßu ti√™n l√† th·ªùi gian

            print(f"   üìÖ S·ª≠ d·ª•ng c·ªôt th·ªùi gian: {time_col}")
            print(f"   üìã T·∫•t c·∫£ c√°c c·ªôt c√≥ s·∫µn: {list(df.columns)}")

            # T·∫°o t·ª´ng bi·ªÉu ƒë·ªì
            for chart_config in charts_config:
                try:
                    if chart_config['type'] == 'line':
                        # Bi·ªÉu ƒë·ªì ƒë∆∞·ªùng ƒë∆°n
                        y_col = self._find_matching_column(df, chart_config['y_col'])
                        if y_col:
                            if data_type == 'hourly':
                                chart_path = self._create_enhanced_hourly_line_chart(
                                    df, time_col, y_col, chart_folder, chart_config['title']
                                )
                            else:
                                chart_path = self._create_enhanced_line_chart(
                                    df, time_col, y_col, chart_folder, chart_config['title']
                                )

                            if chart_path:
                                created_charts.append(chart_path)
                                print(f"   ‚úÖ ƒê√£ t·∫°o bi·ªÉu ƒë·ªì ƒë∆∞·ªùng: {chart_config['title']}")
                            else:
                                print(f"   ‚ùå Kh√¥ng th·ªÉ t·∫°o bi·ªÉu ƒë·ªì ƒë∆∞·ªùng: {chart_config['title']}")
                        else:
                            print(f"   ‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y c·ªôt: {chart_config['y_col']}")

                    elif chart_config['type'] == 'combo':
                        # Bi·ªÉu ƒë·ªì k·∫øt h·ª£p
                        y_line = self._find_matching_column(df, chart_config['y_line'])
                        y_bar = self._find_matching_column(df, chart_config['y_bar'])

                        if y_line and y_bar:
                            if data_type == 'hourly':
                                chart_path = self._create_enhanced_hourly_combo_chart(
                                    df, time_col, y_line, y_bar, chart_folder, chart_config['title']
                                )
                            else:
                                chart_path = self._create_enhanced_combo_chart(
                                    df, time_col, y_line, y_bar, chart_folder, chart_config['title']
                                )

                            if chart_path:
                                created_charts.append(chart_path)
                                print(f"   ‚úÖ ƒê√£ t·∫°o bi·ªÉu ƒë·ªì k·∫øt h·ª£p: {chart_config['title']}")
                            else:
                                print(f"   ‚ùå Kh√¥ng th·ªÉ t·∫°o bi·ªÉu ƒë·ªì k·∫øt h·ª£p: {chart_config['title']}")
                        else:
                            missing_cols = []
                            if not y_line:
                                missing_cols.append(chart_config['y_line'])
                            if not y_bar:
                                missing_cols.append(chart_config['y_bar'])
                            print(f"   ‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y c·ªôt: {', '.join(missing_cols)}")

                except Exception as e:
                    print(f"   ‚ùå L·ªói t·∫°o bi·ªÉu ƒë·ªì '{chart_config['title']}': {e}")
                    continue

        print(f"\nüéâ ƒê√£ t·∫°o t·ªïng c·ªông {len(created_charts)} bi·ªÉu ƒë·ªì c·ª• th·ªÉ!")
        return created_charts

    def _create_enhanced_hourly_line_chart(self, df, x_col, y_col, chart_folder, title):
        """
        T·∫°o bi·ªÉu ƒë·ªì ƒë∆∞·ªùng cho d·ªØ li·ªáu hourly v·ªõi format ƒë·∫∑c bi·ªát
        """
        try:
            # L·ªçc d·ªØ li·ªáu h·ª£p l·ªá
            clean_data = df[[x_col, y_col]].dropna()
            if clean_data.empty:
                return None

            plt.figure(figsize=(16, 8))

            # V·∫Ω bi·ªÉu ƒë·ªì ƒë∆∞·ªùng v·ªõi style ƒë·∫πp h∆°n cho hourly data
            plt.plot(clean_data[x_col], clean_data[y_col],
                     marker='o', linewidth=2, markersize=3,
                     color='#2E86AB', alpha=0.8, markerfacecolor='#A23B72',
                     markeredgecolor='white', markeredgewidth=0.5)

            # ƒê·ªãnh d·∫°ng ti√™u ƒë·ªÅ v√† labels
            plt.title(title, fontsize=16, fontweight='bold', pad=25, color='#2C3E50')
            plt.xlabel('Date and Hour', fontsize=12, fontweight='bold', color='#34495E')
            plt.ylabel(y_col, fontsize=12, fontweight='bold', color='#34495E')

            # Grid v√† styling
            plt.grid(True, alpha=0.4, linestyle='--', linewidth=0.8)
            plt.gca().set_facecolor('#F8F9FA')

            # ƒê·ªãnh d·∫°ng tr·ª•c x ƒë·∫∑c bi·ªát cho hourly data
            if pd.api.types.is_datetime64_any_dtype(clean_data[x_col]):
                # L·∫•y s·ªë ng√†y duy nh·∫•t
                dates = pd.to_datetime(clean_data[x_col].dt.date).unique()
                num_days = len(dates)

                if num_days <= 7:  # √çt h∆°n 1 tu·∫ßn - hi·ªán t·ª´ng gi·ªù
                    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%m/%d\n%H:%M'))
                    plt.gca().xaxis.set_major_locator(mdates.HourLocator(interval=max(1, len(clean_data) // 20)))
                elif num_days <= 31:  # √çt h∆°n 1 th√°ng - hi·ªán m·ªôt s·ªë gi·ªù
                    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%m/%d\n%H:00'))
                    plt.gca().xaxis.set_major_locator(mdates.HourLocator(interval=max(6, len(clean_data) // 30)))
                else:  # Nhi·ªÅu h∆°n - hi·ªán theo ng√†y v·ªõi m·ªôt s·ªë sample gi·ªù
                    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%m/%d'))
                    plt.gca().xaxis.set_major_locator(mdates.DayLocator(interval=max(1, num_days // 15)))

                plt.xticks(rotation=45)

            # Styling cho axes
            ax = plt.gca()
            ax.spines['top'].set_visible(False)
            ax.spines['right'].set_visible(False)
            ax.spines['left'].set_color('#BDC3C7')
            ax.spines['bottom'].set_color('#BDC3C7')

            plt.tight_layout()

            # T·∫°o t√™n file an to√†n
            safe_filename = "".join(c for c in title if c.isalnum() or c in (' ', '-', '_')).replace(' ', '_')
            chart_path = os.path.join(chart_folder, f"{safe_filename}_line.png")
            plt.savefig(chart_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')
            plt.close()

            return chart_path

        except Exception as e:
            plt.close()
            print(f"      ‚ùå L·ªói t·∫°o bi·ªÉu ƒë·ªì ƒë∆∞·ªùng hourly: {e}")
            return None

    def _create_enhanced_hourly_combo_chart(self, df, x_col, y_line, y_bar, chart_folder, title):
        """
        T·∫°o bi·ªÉu ƒë·ªì k·∫øt h·ª£p (ƒë∆∞·ªùng + c·ªôt) cho d·ªØ li·ªáu hourly
        """
        try:
            # L·ªçc d·ªØ li·ªáu h·ª£p l·ªá
            clean_data = df[[x_col, y_line, y_bar]].dropna()
            if clean_data.empty:
                return None

            fig, ax1 = plt.subplots(figsize=(16, 8))
            fig.patch.set_facecolor('white')

            # Tr·ª•c Y b√™n tr√°i (ƒë∆∞·ªùng) - s·ª≠ d·ª•ng gradient color
            color_line = '#E74C3C'
            ax1.set_xlabel('Date and Hour', fontsize=12, fontweight='bold', color='#34495E')
            ax1.set_ylabel(y_line, color=color_line, fontsize=12, fontweight='bold')

            line_plot = ax1.plot(clean_data[x_col], clean_data[y_line],
                                 marker='o', color=color_line, linewidth=2, markersize=3,
                                 label=y_line, alpha=0.9, markerfacecolor='white',
                                 markeredgecolor=color_line, markeredgewidth=1)

            ax1.tick_params(axis='y', labelcolor=color_line, labelsize=10)
            ax1.tick_params(axis='x', labelsize=9, rotation=45)
            ax1.grid(True, alpha=0.3, linestyle='--', linewidth=0.5)

            # Tr·ª•c Y b√™n ph·∫£i (c·ªôt) - s·ª≠ d·ª•ng gradient color
            ax2 = ax1.twinx()
            color_bar = '#3498DB'
            ax2.set_ylabel(y_bar, color=color_bar, fontsize=12, fontweight='bold')

            # T√≠nh ƒë·ªô r·ªông c·ªôt d·ª±a tr√™n s·ªë l∆∞·ª£ng d·ªØ li·ªáu v√† hourly spacing
            if len(clean_data) > 200:  # Nhi·ªÅu d·ªØ li·ªáu hourly
                bar_width = 0.8
                alpha_val = 0.6
            elif len(clean_data) > 100:
                bar_width = 0.9
                alpha_val = 0.65
            else:
                bar_width = 1.0
                alpha_val = 0.7

            # T·∫°o bar width d·ª±a tr√™n time difference
            if pd.api.types.is_datetime64_any_dtype(clean_data[x_col]) and len(clean_data) > 1:
                time_diff = (clean_data[x_col].iloc[1] - clean_data[x_col].iloc[0]).total_seconds() / 3600  # hours
                if time_diff <= 1:  # hourly data
                    bar_width = pd.Timedelta(hours=0.8)
                else:
                    bar_width = pd.Timedelta(hours=time_diff * 0.8)

            bars = ax2.bar(clean_data[x_col], clean_data[y_bar],
                           alpha=alpha_val, color=color_bar, label=y_bar,
                           width=bar_width, edgecolor='white', linewidth=0.5)

            ax2.tick_params(axis='y', labelcolor=color_bar, labelsize=10)

            # Ti√™u ƒë·ªÅ v·ªõi styling ƒë·∫πp
            plt.title(title, fontsize=16, fontweight='bold', pad=25, color='#2C3E50')

            # ƒê·ªãnh d·∫°ng tr·ª•c x ƒë·∫∑c bi·ªát cho hourly data
            if pd.api.types.is_datetime64_any_dtype(clean_data[x_col]):
                # L·∫•y s·ªë ng√†y duy nh·∫•t
                dates = pd.to_datetime(clean_data[x_col].dt.date).unique()
                num_days = len(dates)

                if num_days <= 7:  # √çt h∆°n 1 tu·∫ßn - hi·ªán t·ª´ng gi·ªù
                    ax1.xaxis.set_major_formatter(mdates.DateFormatter('%m/%d\n%H:%M'))
                    ax1.xaxis.set_major_locator(mdates.HourLocator(interval=max(1, len(clean_data) // 20)))
                elif num_days <= 31:  # √çt h∆°n 1 th√°ng - hi·ªán m·ªôt s·ªë gi·ªù
                    ax1.xaxis.set_major_formatter(mdates.DateFormatter('%m/%d\n%H:00'))
                    ax1.xaxis.set_major_locator(mdates.HourLocator(interval=max(6, len(clean_data) // 30)))
                else:  # Nhi·ªÅu h∆°n - hi·ªán theo ng√†y v·ªõi m·ªôt s·ªë sample gi·ªù
                    ax1.xaxis.set_major_formatter(mdates.DateFormatter('%m/%d'))
                    ax1.xaxis.set_major_locator(mdates.DayLocator(interval=max(1, num_days // 15)))

                fig.autofmt_xdate()

            # Legend k·∫øt h·ª£p v·ªõi styling
            lines1, labels1 = ax1.get_legend_handles_labels()
            lines2, labels2 = ax2.get_legend_handles_labels()
            legend = ax1.legend(lines1 + lines2, labels1 + labels2,
                                loc='upper left', fontsize=10,
                                frameon=True, fancybox=True, shadow=True,
                                facecolor='white', edgecolor='#BDC3C7')

            # Styling cho background
            ax1.set_facecolor('#F8F9FA')

            # Lo·∫°i b·ªè spines kh√¥ng c·∫ßn thi·∫øt
            ax1.spines['top'].set_visible(False)
            ax2.spines['top'].set_visible(False)
            ax1.spines['right'].set_visible(False)
            ax2.spines['left'].set_visible(False)

            fig.tight_layout()

            # T·∫°o t√™n file an to√†n
            safe_filename = "".join(c for c in title if c.isalnum() or c in (' ', '-', '_')).replace(' ', '_')
            chart_path = os.path.join(chart_folder, f"{safe_filename}_combo.png")
            plt.savefig(chart_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')
            plt.close()

            return chart_path

        except Exception as e:
            plt.close()
            print(f"      ‚ùå L·ªói t·∫°o bi·ªÉu ƒë·ªì k·∫øt h·ª£p hourly: {e}")
            return None

    def _create_enhanced_line_chart(self, df, x_col, y_col, chart_folder, title):
        """
        T·∫°o bi·ªÉu ƒë·ªì ƒë∆∞·ªùng cho d·ªØ li·ªáu daily
        """
        try:
            # L·ªçc d·ªØ li·ªáu h·ª£p l·ªá
            clean_data = df[[x_col, y_col]].dropna()
            if clean_data.empty:
                return None

            plt.figure(figsize=(14, 8))

            # V·∫Ω bi·ªÉu ƒë·ªì ƒë∆∞·ªùng v·ªõi style ƒë·∫πp h∆°n
            plt.plot(clean_data[x_col], clean_data[y_col],
                     marker='o', linewidth=3, markersize=5,
                     color='#2E86AB', alpha=0.8, markerfacecolor='#A23B72',
                     markeredgecolor='white', markeredgewidth=1)

            # ƒê·ªãnh d·∫°ng ti√™u ƒë·ªÅ v√† labels
            plt.title(title, fontsize=16, fontweight='bold', pad=25, color='#2C3E50')
            plt.xlabel('Date', fontsize=12, fontweight='bold', color='#34495E')
            plt.ylabel(y_col, fontsize=12, fontweight='bold', color='#34495E')

            # Grid v√† styling
            plt.grid(True, alpha=0.4, linestyle='--', linewidth=0.8)
            plt.gca().set_facecolor('#F8F9FA')

            # ƒê·ªãnh d·∫°ng tr·ª•c x cho datetime
            if pd.api.types.is_datetime64_any_dtype(clean_data[x_col]):
                plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%m/%d'))
                plt.gca().xaxis.set_major_locator(mdates.DayLocator(interval=max(1, len(clean_data) // 10)))
                plt.xticks(rotation=45)

            # Styling cho axes
            ax = plt.gca()
            ax.spines['top'].set_visible(False)
            ax.spines['right'].set_visible(False)
            ax.spines['left'].set_color('#BDC3C7')
            ax.spines['bottom'].set_color('#BDC3C7')

            plt.tight_layout()

            # T·∫°o t√™n file an to√†n
            safe_filename = "".join(c for c in title if c.isalnum() or c in (' ', '-', '_')).replace(' ', '_')
            chart_path = os.path.join(chart_folder, f"{safe_filename}_line.png")
            plt.savefig(chart_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')
            plt.close()

            return chart_path

        except Exception as e:
            plt.close()
            print(f"      ‚ùå L·ªói t·∫°o bi·ªÉu ƒë·ªì ƒë∆∞·ªùng: {e}")
            return None

    def _create_enhanced_combo_chart(self, df, x_col, y_line, y_bar, chart_folder, title):
        """
        T·∫°o bi·ªÉu ƒë·ªì k·∫øt h·ª£p (ƒë∆∞·ªùng + c·ªôt) cho d·ªØ li·ªáu daily
        """
        try:
            # L·ªçc d·ªØ li·ªáu h·ª£p l·ªá
            clean_data = df[[x_col, y_line, y_bar]].dropna()
            if clean_data.empty:
                return None

            fig, ax1 = plt.subplots(figsize=(14, 8))
            fig.patch.set_facecolor('white')

            # Tr·ª•c Y b√™n tr√°i (ƒë∆∞·ªùng) - s·ª≠ d·ª•ng gradient color
            color_line = '#E74C3C'
            ax1.set_xlabel('Date', fontsize=12, fontweight='bold', color='#34495E')
            ax1.set_ylabel(y_line, color=color_line, fontsize=12, fontweight='bold')

            line_plot = ax1.plot(clean_data[x_col], clean_data[y_line],
                                 marker='o', color=color_line, linewidth=3, markersize=5,
                                 label=y_line, alpha=0.9, markerfacecolor='white',
                                 markeredgecolor=color_line, markeredgewidth=2)

            ax1.tick_params(axis='y', labelcolor=color_line, labelsize=10)
            ax1.tick_params(axis='x', labelsize=10, rotation=45)
            ax1.grid(True, alpha=0.3, linestyle='--', linewidth=0.5)

            # Tr·ª•c Y b√™n ph·∫£i (c·ªôt) - s·ª≠ d·ª•ng gradient color
            ax2 = ax1.twinx()
            color_bar = '#3498DB'
            ax2.set_ylabel(y_bar, color=color_bar, fontsize=12, fontweight='bold')

            # T√≠nh ƒë·ªô r·ªông c·ªôt d·ª±a tr√™n s·ªë l∆∞·ª£ng d·ªØ li·ªáu
            if len(clean_data) > 30:
                bar_width = 0.4
            elif len(clean_data) > 15:
                bar_width = 0.6
            else:
                bar_width = 0.8

            bars = ax2.bar(clean_data[x_col], clean_data[y_bar],
                           alpha=0.7, color=color_bar, label=y_bar,
                           width=bar_width, edgecolor='white', linewidth=0.5)

            ax2.tick_params(axis='y', labelcolor=color_bar, labelsize=10)

            # Ti√™u ƒë·ªÅ v·ªõi styling ƒë·∫πp
            plt.title(title, fontsize=16, fontweight='bold', pad=25, color='#2C3E50')

            # ƒê·ªãnh d·∫°ng tr·ª•c x
            if pd.api.types.is_datetime64_any_dtype(clean_data[x_col]):
                fig.autofmt_xdate()
                ax1.xaxis.set_major_formatter(mdates.DateFormatter('%m/%d'))
                ax1.xaxis.set_major_locator(mdates.DayLocator(interval=max(1, len(clean_data) // 10)))

            # Legend k·∫øt h·ª£p v·ªõi styling
            lines1, labels1 = ax1.get_legend_handles_labels()
            lines2, labels2 = ax2.get_legend_handles_labels()
            legend = ax1.legend(lines1 + lines2, labels1 + labels2,
                                loc='upper left', fontsize=11,
                                frameon=True, fancybox=True, shadow=True,
                                facecolor='white', edgecolor='#BDC3C7')

            # Styling cho background
            ax1.set_facecolor('#F8F9FA')

            # Lo·∫°i b·ªè spines kh√¥ng c·∫ßn thi·∫øt
            ax1.spines['top'].set_visible(False)
            ax2.spines['top'].set_visible(False)
            ax1.spines['right'].set_visible(False)
            ax2.spines['left'].set_visible(False)

            fig.tight_layout()

            # T·∫°o t√™n file an to√†n
            safe_filename = "".join(c for c in title if c.isalnum() or c in (' ', '-', '_')).replace(' ', '_')
            chart_path = os.path.join(chart_folder, f"{safe_filename}_combo.png")
            plt.savefig(chart_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')
            plt.close()

            return chart_path

        except Exception as e:
            plt.close()
            print(f"      ‚ùå L·ªói t·∫°o bi·ªÉu ƒë·ªì k·∫øt h·ª£p: {e}")
            return None

    def create_comprehensive_report(self, output_dir="output_charts"):
        """
        T·∫°o b√°o c√°o t·ªïng h·ª£p v·ªõi t·∫•t c·∫£ c√°c bi·ªÉu ƒë·ªì c·ª• th·ªÉ
        """
        print(f"\nüìã T·∫°o b√°o c√°o t·ªïng h·ª£p v·ªõi c√°c bi·ªÉu ƒë·ªì c·ª• th·ªÉ...")

        try:
            # Thu th·∫≠p t·∫•t c·∫£ file ·∫£nh bi·ªÉu ƒë·ªì
            image_files = []

            # Bi·ªÉu ƒë·ªì Daily
            daily_chart_dir = os.path.join(output_dir, "Chart_daily")
            if os.path.exists(daily_chart_dir):
                daily_files = []
                for file in sorted(os.listdir(daily_chart_dir)):
                    if file.endswith('.png'):
                        daily_files.append(os.path.join(daily_chart_dir, file))
                image_files.extend(daily_files)
                print(f"   üìä T√¨m th·∫•y {len(daily_files)} bi·ªÉu ƒë·ªì Daily")

            # Bi·ªÉu ƒë·ªì Hourly
            hourly_chart_dir = os.path.join(output_dir, "Chart_hourly")
            if os.path.exists(hourly_chart_dir):
                hourly_files = []
                for file in sorted(os.listdir(hourly_chart_dir)):
                    if file.endswith('.png'):
                        hourly_files.append(os.path.join(hourly_chart_dir, file))
                image_files.extend(hourly_files)
                print(f"   üìä T√¨m th·∫•y {len(hourly_files)} bi·ªÉu ƒë·ªì Hourly")

            if not image_files:
                print("   ‚ùå Kh√¥ng t√¨m th·∫•y file ·∫£nh n√†o ƒë·ªÉ t·∫°o b√°o c√°o")
                return None

            print(f"   üìä T·ªïng c·ªông {len(image_files)} bi·ªÉu ƒë·ªì s·∫Ω ƒë∆∞·ª£c ƒë∆∞a v√†o b√°o c√°o")

            # T·∫°o b√°o c√°o ƒëa trang n·∫øu c√≥ nhi·ªÅu bi·ªÉu ƒë·ªì
            if len(image_files) <= 9:
                report_path = self._create_single_page_report(image_files, output_dir)
            else:
                report_path = self._create_multi_page_report(image_files, output_dir)

            if report_path:
                print(f"‚úÖ ƒê√£ t·∫°o b√°o c√°o t·ªïng h·ª£p: {report_path}")

                # T·∫°o PDF t·ª´ PNG
                try:
                    if isinstance(report_path, list):
                        # Multi-page report
                        pdf_path = os.path.join(output_dir, "VoLTE_KPI_Multi_Page_Report.pdf")
                        self._create_multi_page_pdf(report_path, pdf_path)
                    else:
                        # Single-page report
                        pdf_path = report_path.replace('.png', '.pdf')
                        img = Image.open(report_path)
                        img.save(pdf_path, "PDF", quality=95)

                    print(f"‚úÖ ƒê√£ t·∫°o b√°o c√°o PDF: {pdf_path}")
                except Exception as e:
                    print(f"‚ö†Ô∏è Kh√¥ng th·ªÉ t·∫°o PDF: {e}")

            return report_path

        except Exception as e:
            print(f"‚ùå L·ªói t·∫°o b√°o c√°o t·ªïng h·ª£p: {e}")
            return None

    def _create_single_page_report(self, image_files, output_dir):
        """
        T·∫°o b√°o c√°o single page cho √≠t bi·ªÉu ƒë·ªì
        """
        try:
            if not image_files:
                return None

            # ƒê·ªçc t·∫•t c·∫£ ·∫£nh
            images = []
            for img_path in image_files:
                try:
                    img = Image.open(img_path)
                    images.append((img, os.path.basename(img_path)))
                except Exception as e:
                    print(f"   ‚ö†Ô∏è Kh√¥ng th·ªÉ ƒë·ªçc {img_path}: {e}")

            if not images:
                return None

            # C·∫•u h√¨nh layout cho trang A4
            page_width = 2100
            page_height = 2970
            margin = 60
            header_height = 150
            footer_height = 80
            spacing = 40

            # Layout d·ª±a tr√™n s·ªë l∆∞·ª£ng bi·ªÉu ƒë·ªì
            if len(images) <= 4:
                cols, rows = 2, 2
            elif len(images) <= 6:
                cols, rows = 2, 3
            else:  # <= 9
                cols, rows = 3, 3

            # Ch·ªâ l·∫•y s·ªë bi·ªÉu ƒë·ªì v·ª´a ƒë·ªß
            images = images[:cols * rows]

            # T√≠nh k√≠ch th∆∞·ªõc bi·ªÉu ƒë·ªì
            available_width = page_width - 2 * margin - (cols - 1) * spacing
            available_height = page_height - header_height - footer_height - 2 * margin - (rows - 1) * spacing

            chart_width = available_width // cols
            chart_height = available_height // rows

            # T·∫°o canvas
            report_img = Image.new('RGB', (page_width, page_height), 'white')
            draw = ImageDraw.Draw(report_img)

            # Font setup
            try:
                title_font = ImageFont.truetype("arial.ttf", 42)
                subtitle_font = ImageFont.truetype("arial.ttf", 22)
                page_font = ImageFont.truetype("arial.ttf", 18)
            except:
                title_font = ImageFont.load_default()
                subtitle_font = ImageFont.load_default()
                page_font = ImageFont.load_default()

            # Header
            title = "VoLTE KPI COMPREHENSIVE ANALYSIS REPORT"
            title_bbox = draw.textbbox((0, 0), title, font=title_font)
            title_width = title_bbox[2] - title_bbox[0]
            draw.text(((page_width - title_width) // 2, margin), title,
                      fill='#2C3E50', font=title_font)

            # Subtitle
            subtitle = f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M')} | Charts: {len(images)}"
            subtitle_bbox = draw.textbbox((0, 0), subtitle, font=subtitle_font)
            subtitle_width = subtitle_bbox[2] - subtitle_bbox[0]
            draw.text(((page_width - subtitle_width) // 2, margin + 55), subtitle,
                      fill='#7F8C8D', font=subtitle_font)

            # Separator line
            line_y = header_height + margin - 20
            draw.line([(margin, line_y), (page_width - margin, line_y)], fill='#BDC3C7', width=3)

            # V·∫Ω c√°c bi·ªÉu ƒë·ªì
            start_y = header_height + margin

            for i, (chart_img, filename) in enumerate(images):
                row = i // cols
                col = i % cols

                x = margin + col * (chart_width + spacing)
                y = start_y + row * (chart_height + spacing)

                # Resize bi·ªÉu ƒë·ªì
                chart_resized = self._resize_image_proportional(chart_img, chart_width - 20, chart_height - 40)

                # CƒÉn gi·ªØa
                chart_w, chart_h = chart_resized.size
                center_x = x + (chart_width - chart_w) // 2
                center_y = y + (chart_height - chart_h) // 2

                # V·∫Ω background cho bi·ªÉu ƒë·ªì
                bg_rect = [x + 5, y + 5, x + chart_width - 5, y + chart_height - 5]
                draw.rectangle(bg_rect, fill='#F8F9FA', outline='#E5E5E5', width=2)

                # Paste bi·ªÉu ƒë·ªì
                report_img.paste(chart_resized, (center_x, center_y))

                # Title cho bi·ªÉu ƒë·ªì (truncate n·∫øu qu√° d√†i)
                chart_title = filename.replace('.png', '').replace('_', ' ')
                if len(chart_title) > 40:
                    chart_title = chart_title[:37] + "..."

                title_bbox = draw.textbbox((0, 0), chart_title, font=page_font)
                title_width = title_bbox[2] - title_bbox[0]
                title_x = x + (chart_width - title_width) // 2
                draw.text((title_x, y + chart_height - 35), chart_title,
                          fill='#34495E', font=page_font)

            # Footer
            footer_text = f"VoLTE KPI Analysis | Total Charts: {len(images)}"
            footer_bbox = draw.textbbox((0, 0), footer_text, font=subtitle_font)
            footer_width = footer_bbox[2] - footer_bbox[0]
            draw.text(((page_width - footer_width) // 2, page_height - footer_height), footer_text,
                      fill='#95A5A6', font=subtitle_font)

            # L∆∞u b√°o c√°o
            report_path = os.path.join(output_dir, "VoLTE_KPI_Single_Page_Report.png")
            report_img.save(report_path, "PNG", quality=95, dpi=(300, 300))

            return report_path

        except Exception as e:
            print(f"‚ùå L·ªói t·∫°o b√°o c√°o single page: {e}")
            return None

    def _create_multi_page_report(self, image_files, output_dir):
        """
        T·∫°o b√°o c√°o nhi·ªÅu trang cho nhi·ªÅu bi·ªÉu ƒë·ªì
        """
        try:
            charts_per_page = 6  # S·ªë bi·ªÉu ƒë·ªì t·ªëi ƒëa m·ªói trang
            total_pages = math.ceil(len(image_files) / charts_per_page)

            print(f"   üìÑ T·∫°o b√°o c√°o {total_pages} trang v·ªõi {len(image_files)} bi·ªÉu ƒë·ªì")

            page_files = []

            for page_num in range(total_pages):
                start_idx = page_num * charts_per_page
                end_idx = min(start_idx + charts_per_page, len(image_files))
                page_images = image_files[start_idx:end_idx]

                page_path = self._create_report_page(page_images, output_dir, page_num + 1, total_pages)
                if page_path:
                    page_files.append(page_path)

            return page_files

        except Exception as e:
            print(f"‚ùå L·ªói t·∫°o b√°o c√°o nhi·ªÅu trang: {e}")
            return None

    def _create_report_page(self, image_files, output_dir, page_num, total_pages):
        """
        T·∫°o m·ªôt trang b√°o c√°o
        """
        try:
            if not image_files:
                return None

            # ƒê·ªçc t·∫•t c·∫£ ·∫£nh
            images = []
            for img_path in image_files:
                try:
                    img = Image.open(img_path)
                    images.append((img, os.path.basename(img_path)))
                except Exception as e:
                    print(f"   ‚ö†Ô∏è Kh√¥ng th·ªÉ ƒë·ªçc {img_path}: {e}")

            if not images:
                return None

            # C·∫•u h√¨nh layout cho trang A4
            page_width = 2100
            page_height = 2970
            margin = 60
            header_height = 150
            footer_height = 80
            spacing = 40

            # Layout cho 6 bi·ªÉu ƒë·ªì: 2 c·ªôt x 3 h√†ng
            cols = 2
            rows = 3

            # Ch·ªâ l·∫•y t·ªëi ƒëa 6 bi·ªÉu ƒë·ªì
            images = images[:6]

            # T√≠nh k√≠ch th∆∞·ªõc bi·ªÉu ƒë·ªì
            available_width = page_width - 2 * margin - (cols - 1) * spacing
            available_height = page_height - header_height - footer_height - 2 * margin - (rows - 1) * spacing

            chart_width = available_width // cols
            chart_height = available_height // rows

            # T·∫°o canvas
            report_img = Image.new('RGB', (page_width, page_height), 'white')
            draw = ImageDraw.Draw(report_img)

            # Font setup
            try:
                title_font = ImageFont.truetype("arial.ttf", 42)
                subtitle_font = ImageFont.truetype("arial.ttf", 22)
                page_font = ImageFont.truetype("arial.ttf", 18)
            except:
                title_font = ImageFont.load_default()
                subtitle_font = ImageFont.load_default()
                page_font = ImageFont.load_default()

            # Header
            title = "VoLTE KPI COMPREHENSIVE ANALYSIS REPORT"
            title_bbox = draw.textbbox((0, 0), title, font=title_font)
            title_width = title_bbox[2] - title_bbox[0]
            draw.text(((page_width - title_width) // 2, margin), title,
                      fill='#2C3E50', font=title_font)

            # Subtitle
            subtitle = f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M')} | Page {page_num}/{total_pages}"
            subtitle_bbox = draw.textbbox((0, 0), subtitle, font=subtitle_font)
            subtitle_width = subtitle_bbox[2] - subtitle_bbox[0]
            draw.text(((page_width - subtitle_width) // 2, margin + 55), subtitle,
                      fill='#7F8C8D', font=subtitle_font)

            # Separator line
            line_y = header_height + margin - 20
            draw.line([(margin, line_y), (page_width - margin, line_y)], fill='#BDC3C7', width=3)

            # V·∫Ω c√°c bi·ªÉu ƒë·ªì
            start_y = header_height + margin

            for i, (chart_img, filename) in enumerate(images):
                row = i // cols
                col = i % cols

                x = margin + col * (chart_width + spacing)
                y = start_y + row * (chart_height + spacing)

                # Resize bi·ªÉu ƒë·ªì
                chart_resized = self._resize_image_proportional(chart_img, chart_width - 20, chart_height - 40)

                # CƒÉn gi·ªØa
                chart_w, chart_h = chart_resized.size
                center_x = x + (chart_width - chart_w) // 2
                center_y = y + (chart_height - chart_h) // 2

                # V·∫Ω background cho bi·ªÉu ƒë·ªì
                bg_rect = [x + 5, y + 5, x + chart_width - 5, y + chart_height - 5]
                draw.rectangle(bg_rect, fill='#F8F9FA', outline='#E5E5E5', width=2)

                # Paste bi·ªÉu ƒë·ªì
                report_img.paste(chart_resized, (center_x, center_y))

                # Title cho bi·ªÉu ƒë·ªì (truncate n·∫øu qu√° d√†i)
                chart_title = filename.replace('.png', '').replace('_', ' ')
                if len(chart_title) > 40:
                    chart_title = chart_title[:37] + "..."

                title_bbox = draw.textbbox((0, 0), chart_title, font=page_font)
                title_width = title_bbox[2] - title_bbox[0]
                title_x = x + (chart_width - title_width) // 2
                draw.text((title_x, y + chart_height - 35), chart_title,
                          fill='#34495E', font=page_font)

            # Footer
            footer_text = f"VoLTE KPI Analysis | Charts on this page: {len(images)}"
            footer_bbox = draw.textbbox((0, 0), footer_text, font=subtitle_font)
            footer_width = footer_bbox[2] - footer_bbox[0]
            draw.text(((page_width - footer_width) // 2, page_height - footer_height), footer_text,
                      fill='#95A5A6', font=subtitle_font)

            # L∆∞u trang
            page_path = os.path.join(output_dir, f"VoLTE_KPI_Report_Page_{page_num}.png")
            report_img.save(page_path, "PNG", quality=95, dpi=(300, 300))

            return page_path

        except Exception as e:
            print(f"‚ùå L·ªói t·∫°o trang b√°o c√°o {page_num}: {e}")
            return None

    def _create_multi_page_pdf(self, page_files, pdf_path):
        """
        T·∫°o PDF t·ª´ nhi·ªÅu trang PNG
        """
        try:
            if not page_files:
                return False

            images = []
            for page_file in page_files:
                img = Image.open(page_file)
                images.append(img)

            # L∆∞u PDF
            images[0].save(pdf_path, "PDF", save_all=True, append_images=images[1:], quality=95)
            return True

        except Exception as e:
            print(f"‚ùå L·ªói t·∫°o PDF nhi·ªÅu trang: {e}")
            return False

    def _resize_image_proportional(self, img, max_width, max_height):
        """
        Resize ·∫£nh gi·ªØ nguy√™n t·ªâ l·ªá
        """
        original_width, original_height = img.size
        ratio_w = max_width / original_width
        ratio_h = max_height / original_height
        ratio = min(ratio_w, ratio_h)

        new_width = int(original_width * ratio)
        new_height = int(original_height * ratio)

        return img.resize((new_width, new_height), Image.Resampling.LANCZOS)

    def process_complete_workflow(self, excel_path, output_dir="output_charts"):
        """
        Th·ª±c hi·ªán quy tr√¨nh ho√†n ch·ªânh v·ªõi bi·ªÉu ƒë·ªì c·ª• th·ªÉ
        """
        print(f"\nüéØ B·∫ÆT ƒê·∫¶U QUY TR√åNH X·ª¨ L√ù HO√ÄN CH·ªàNH - ENHANCED VERSION WITH FIXED HOURLY CHARTS")
        print(f"üìÅ File ƒë·∫ßu v√†o: {excel_path}")
        print(f"üìÅ Th∆∞ m·ª•c ƒë·∫ßu ra: {output_dir}")
        print("=" * 70)

        # B∆∞·ªõc 1: ƒê·ªçc Excel
        print("\nüìñ B∆Ø·ªöC 1: ƒê·ªåC V√Ä PH√ÇN T√çCH FILE EXCEL")
        dataframes = self.read_excel_file(excel_path)

        if not dataframes:
            print("‚ùå Kh√¥ng th·ªÉ ƒë·ªçc file Excel!")
            return False

        # B∆∞·ªõc 2: L√†m s·∫°ch d·ªØ li·ªáu
        print("\nüßπ B∆Ø·ªöC 2: L√ÄM S·∫†CH D·ªÆ LI·ªÜU V·ªöI C·∫¢I THI·ªÜN CHO HOURLY")
        cleaned_dataframes = {}

        for sheet_name, df in dataframes.items():
            cleaned_df = self.clean_dataframe_enhanced(df, sheet_name)
            if cleaned_df is not None and not cleaned_df.empty:
                cleaned_dataframes[sheet_name] = cleaned_df
            else:
                print(f"‚ùå Kh√¥ng th·ªÉ l√†m s·∫°ch d·ªØ li·ªáu t·ª´ {sheet_name}")

        if not cleaned_dataframes:
            print("‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu h·ª£p l·ªá sau khi l√†m s·∫°ch!")
            return False

        # B∆∞·ªõc 3: L∆∞u CSV
        print("\nüíæ B∆Ø·ªöC 3: L∆ØU D·ªÆ LI·ªÜU TH√ÄNH CSV")
        csv_files = self.save_to_csv(cleaned_dataframes, output_dir)

        if not csv_files:
            print("‚ùå Kh√¥ng th·ªÉ l∆∞u file CSV!")
            return False

        # B∆∞·ªõc 4: T·∫°o bi·ªÉu ƒë·ªì c·ª• th·ªÉ v·ªõi c·∫£i thi·ªán hourly
        print("\nüé® B∆Ø·ªöC 4: T·∫†O C√ÅC BI·ªÇU ƒê·ªí C·ª§ TH·ªÇ V·ªöI HOURLY CHARTS C·∫¢I THI·ªÜN")
        created_charts = self.create_specific_charts(output_dir)

        if not created_charts:
            print("‚ö†Ô∏è Kh√¥ng t·∫°o ƒë∆∞·ª£c bi·ªÉu ƒë·ªì n√†o!")
            return False

        # B∆∞·ªõc 5: T·∫°o b√°o c√°o t·ªïng h·ª£p
        print("\nüìã B∆Ø·ªöC 5: T·∫†O B√ÅO C√ÅO T·ªîNG H·ª¢P")
        report_path = self.create_comprehensive_report(output_dir)

        # T·ªïng k·∫øt
        print("\n" + "=" * 70)
        print("üéâ HO√ÄN T·∫§T QUY TR√åNH X·ª¨ L√ù N√ÇNG CAO V·ªöI HOURLY CHARTS C·∫¢I THI·ªÜN!")
        print("=" * 70)
        print(f"üìÅ K·∫øt qu·∫£ l∆∞u t·∫°i: {output_dir}")
        print(f"üìä ƒê√£ t·∫°o {len(created_charts)} bi·ªÉu ƒë·ªì c·ª• th·ªÉ")

        print("\nüìä C·∫•u tr√∫c k·∫øt qu·∫£:")
        print("üìÇ output_charts/")

        # Hi·ªÉn th·ªã CSV files
        for sheet_name, csv_path in csv_files.items():
            print(f"   üìÑ {os.path.basename(csv_path)}")

        # Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì
        chart_folders = ['Chart_daily', 'Chart_hourly']
        for folder in chart_folders:
            folder_path = os.path.join(output_dir, folder)
            if os.path.exists(folder_path):
                chart_count = len([f for f in os.listdir(folder_path) if f.endswith('.png')])
                print(f"   üìÇ {folder}/ ({chart_count} bi·ªÉu ƒë·ªì c·ª• th·ªÉ)")

        # Hi·ªÉn th·ªã b√°o c√°o
        if report_path:
            if isinstance(report_path, list):
                print(f"   üìä VoLTE_KPI_Report_Page_*.png ({len(report_path)} trang)")
                print(f"   üìä VoLTE_KPI_Multi_Page_Report.pdf")
            else:
                print(f"   üìä {os.path.basename(report_path)}")
                pdf_path = report_path.replace('.png', '.pdf')
                if os.path.exists(pdf_path):
                    print(f"   üìä {os.path.basename(pdf_path)}")

        print("\n‚ú® C·∫£i thi·ªán ƒë·∫∑c bi·ªát cho Hourly Charts:")
        print("   üïê X·ª≠ l√Ω datetime ch√≠nh x√°c cho d·ªØ li·ªáu hourly")
        print("   üìÖ Format tr·ª•c th·ªùi gian ph√π h·ª£p v·ªõi hourly data")
        print("   üìä Bar width t·ª± ƒë·ªông ƒëi·ªÅu ch·ªânh theo density d·ªØ li·ªáu")
        print("   üé® Styling t·ªëi ∆∞u cho visualization hourly data")

        print("\n‚ú® C√°c bi·ªÉu ƒë·ªì ƒë∆∞·ª£c t·∫°o theo ƒë√∫ng y√™u c·∫ßu:")
        print("   üìà VoLTE Traffic (Erl) - Line charts (Daily & Hourly)")
        print("   üìä SRVCC HOSR & Att - Combo charts (Daily & Hourly)")
        print("   üìä VoLTE CSSR & RAB Att QCI1/QCI5 - Combo charts (Daily & Hourly)")
        print("   üìä VoLTE CDR & Call Drop QCI1/QCI5 - Combo charts (Daily & Hourly)")
        print("   üìä VOLTE UL/DL Packet Loss - Combo charts (Daily & Hourly)")
        print("=" * 70)

        return True


def main():
    """
    H√†m main ƒë·ªÉ ch·∫°y ch∆∞∆°ng tr√¨nh v·ªõi c√°c bi·ªÉu ƒë·ªì c·ª• th·ªÉ v√† c·∫£i thi·ªán hourly
    """
    print("üöÄ VOLTE KPI DATA PROCESSING SYSTEM - ENHANCED VERSION WITH FIXED HOURLY CHARTS")
    print("=" * 70)
    print("üìã Ch·ª©c nƒÉng n√¢ng cao:")
    print("   ‚úÖ Chuy·ªÉn ƒë·ªïi Excel sang CSV")
    print("   ‚úÖ L√†m s·∫°ch d·ªØ li·ªáu chuy√™n s√¢u")
    print("   ‚úÖ X·ª≠ l√Ω datetime ch√≠nh x√°c cho hourly data")
    print("   ‚úÖ T·∫°o c√°c bi·ªÉu ƒë·ªì C·ª§ TH·ªÇ theo y√™u c·∫ßu:")
    print("      üìà VoLTE Traffic (Erl) - Bi·ªÉu ƒë·ªì ƒë∆∞·ªùng")
    print("      üìä SRVCC HOSR & HO Att - Bi·ªÉu ƒë·ªì k·∫øt h·ª£p")
    print("      üìä VoLTE CSSR & RAB Att QCI1/QCI5 - Bi·ªÉu ƒë·ªì k·∫øt h·ª£p")
    print("      üìä VoLTE CDR & Call Drop QCI1/QCI5 - Bi·ªÉu ƒë·ªì k·∫øt h·ª£p")
    print("      üìä VOLTE UL/DL Packet Loss - Bi·ªÉu ƒë·ªì k·∫øt h·ª£p")
    print("   ‚úÖ Format ƒë·∫∑c bi·ªát cho bi·ªÉu ƒë·ªì hourly")
    print("   ‚úÖ T·∫°o b√°o c√°o t·ªïng h·ª£p PNG/PDF (ƒë∆°n trang ho·∫∑c nhi·ªÅu trang)")
    print("=" * 70)

    # Kh·ªüi t·∫°o processor
    processor = VoLTEKPIProcessor()

    # ƒê∆∞·ªùng d·∫´n file Excel
    excel_file = "4G_KPI Cell VoLTE_ThanhTT.xlsx"

    # Ki·ªÉm tra file t·ªìn t·∫°i
    if not os.path.exists(excel_file):
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y file: {excel_file}")
        print("üí° H√£y ƒë·∫£m b·∫£o file Excel ·ªü c√πng th∆∞ m·ª•c v·ªõi script n√†y")
        print("üí° Ho·∫∑c thay ƒë·ªïi ƒë∆∞·ªùng d·∫´n trong bi·∫øn excel_file")
        return

    # Ch·∫°y quy tr√¨nh ho√†n ch·ªânh
    success = processor.process_complete_workflow(excel_file)

    if success:
        print("\nüéä TH√ÄNH C√îNG! H√£y ki·ªÉm tra th∆∞ m·ª•c 'output_charts'")
        print("üìä T·∫•t c·∫£ c√°c bi·ªÉu ƒë·ªì c·ª• th·ªÉ ƒë√£ ƒë∆∞·ª£c t·∫°o theo ƒë√∫ng y√™u c·∫ßu")
        print("üïê Bi·ªÉu ƒë·ªì hourly ƒë√£ ƒë∆∞·ª£c c·∫£i thi·ªán v·ªõi format th·ªùi gian ch√≠nh x√°c")
        print("üìÑ B√°o c√°o t·ªïng h·ª£p ƒë∆∞·ª£c l∆∞u d·∫°ng PNG v√† PDF")
    else:
        print("\n‚ùå C√ì L·ªñI X·∫¢Y RA! Vui l√≤ng ki·ªÉm tra l·∫°i d·ªØ li·ªáu ƒë·∫ßu v√†o")


if __name__ == "__main__":
    # Ki·ªÉm tra c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt
    required_packages = {
        'pandas': 'pandas',
        'matplotlib': 'matplotlib',
        'numpy': 'numpy',
        'PIL': 'Pillow',
        'openpyxl': 'openpyxl'
    }

    print("üì¶ Ki·ªÉm tra th∆∞ vi·ªán c·∫ßn thi·∫øt:")
    missing_packages = []

    for package, install_name in required_packages.items():
        try:
            __import__(package)
            print(f"   ‚úÖ {package}")
        except ImportError:
            print(f"   ‚ùå {package} - C·∫ßn c√†i ƒë·∫∑t: pip install {install_name}")
            missing_packages.append(install_name)

    if missing_packages:
        print(f"\n‚ö†Ô∏è Vui l√≤ng c√†i ƒë·∫∑t c√°c package c√≤n thi·∫øu:")
        print(f"pip install {' '.join(missing_packages)}")
        exit()

    print("\n")
    main()