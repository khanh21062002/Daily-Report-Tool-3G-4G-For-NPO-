import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import numpy as np
import os
import warnings
from datetime import datetime, timedelta
from PIL import Image, ImageDraw, ImageFont
import math

# T·∫Øt warnings ƒë·ªÉ output s·∫°ch h∆°n
warnings.filterwarnings('ignore')


class VoLTEKPIProcessor:
    def __init__(self):
        """
        Kh·ªüi t·∫°o class processor v·ªõi c·∫•u h√¨nh matplotlib ti·∫øng Vi·ªát
        """
        # C·∫•u h√¨nh matplotlib ƒë·ªÉ hi·ªÉn th·ªã ti·∫øng Vi·ªát
        plt.rcParams['font.family'] = 'DejaVu Sans'
        plt.rcParams['axes.unicode_minus'] = False

        self.cleaned_data = {}
        self.csv_files = {}

        print("VOLTE KPI DATA PROCESSOR")
        print("=" * 70)

    def read_excel_file(self, excel_path):
        """
        ƒê·ªçc file Excel v√† x√°c ƒë·ªãnh c√°c sheets c·∫ßn x·ª≠ l√Ω
        """
        try:
            print(f"üìñ ƒêang ƒë·ªçc file Excel: {excel_path}")

            # ƒê·ªçc t·∫•t c·∫£ sheet names
            excel_file = pd.ExcelFile(excel_path)
            all_sheets = excel_file.sheet_names
            print(f"üìä T·∫•t c·∫£ sheets: {all_sheets}")

            # X√°c ƒë·ªãnh c√°c sheet d·ªØ li·ªáu c·∫ßn x·ª≠ l√Ω (ch·ªâ 2 sheet ƒë·∫ßu ti√™n)
            target_sheets = ["Net KPI_Daily", "Net KPI_Hourly"]

            # T√¨m sheets c√≥ s·∫µn
            available_sheets = []
            for sheet in target_sheets:
                if sheet in all_sheets:
                    available_sheets.append(sheet)
                    print(f"‚úÖ T√¨m th·∫•y sheet: {sheet}")
                else:
                    # T√¨m sheet t∆∞∆°ng t·ª±
                    similar_sheet = self._find_similar_sheet(sheet, all_sheets)
                    if similar_sheet:
                        available_sheets.append(similar_sheet)
                        print(f"‚úÖ T√¨m th·∫•y sheet t∆∞∆°ng t·ª±: {similar_sheet}")
                    else:
                        print(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y sheet: {sheet}")

            if not available_sheets:
                print("‚ùå Kh√¥ng t√¨m th·∫•y sheet d·ªØ li·ªáu c·∫ßn thi·∫øt!")
                return None

            # ƒê·ªçc d·ªØ li·ªáu t·ª´ c√°c sheets
            dataframes = {}
            for sheet_name in available_sheets:
                print(f"üìñ ƒêang ƒë·ªçc sheet: {sheet_name}")

                # ƒê·ªçc v·ªõi nhi·ªÅu ph∆∞∆°ng ph√°p ƒë·ªÉ tr√°nh l·ªói
                df = self._read_sheet_robust(excel_file, sheet_name)

                if df is not None and not df.empty:
                    dataframes[sheet_name] = df
                    print(f"   üìä K√≠ch th∆∞·ªõc raw: {df.shape}")
                else:
                    print(f"   ‚ùå Kh√¥ng th·ªÉ ƒë·ªçc d·ªØ li·ªáu t·ª´ {sheet_name}")

            return dataframes

        except Exception as e:
            print(f"‚ùå L·ªói khi ƒë·ªçc file Excel: {e}")
            return None

    def _find_similar_sheet(self, target_sheet, all_sheets):
        """
        T√¨m sheet c√≥ t√™n t∆∞∆°ng t·ª±
        """
        target_lower = target_sheet.lower()
        for sheet in all_sheets:
            sheet_lower = sheet.lower()
            if any(keyword in sheet_lower for keyword in ['daily', 'hourly', 'kpi']):
                if 'daily' in target_lower and 'daily' in sheet_lower:
                    return sheet
                elif 'hourly' in target_lower and ('hourly' in sheet_lower or 'hour' in sheet_lower):
                    return sheet
        return None

    def _read_sheet_robust(self, excel_file, sheet_name):
        """
        ƒê·ªçc sheet v·ªõi nhi·ªÅu ph∆∞∆°ng ph√°p ƒë·ªÉ ƒë·∫£m b·∫£o th√†nh c√¥ng
        """
        try:
            # Th·ª≠ ƒë·ªçc v·ªõi header m·∫∑c ƒë·ªãnh
            df = pd.read_excel(excel_file, sheet_name=sheet_name, header=0)

            # Ki·ªÉm tra xem c√≥ ph·∫£i header th·ª±c s·ª± kh√¥ng
            if self._is_valid_header(df):
                return df

            # N·∫øu kh√¥ng, th·ª≠ t√¨m header th·ª±c s·ª±
            for header_row in range(0, min(10, len(df))):
                try:
                    df_test = pd.read_excel(excel_file, sheet_name=sheet_name, header=header_row)
                    if self._is_valid_header(df_test):
                        print(f"   üéØ T√¨m th·∫•y header th·ª±c t·∫ø ·ªü d√≤ng {header_row}")
                        return df_test
                except:
                    continue

            # N·∫øu v·∫´n kh√¥ng t√¨m ƒë∆∞·ª£c, s·ª≠ d·ª•ng ph∆∞∆°ng ph√°p cu·ªëi c√πng
            df = pd.read_excel(excel_file, sheet_name=sheet_name, header=None)
            return df

        except Exception as e:
            print(f"   ‚ùå L·ªói khi ƒë·ªçc sheet {sheet_name}: {e}")
            return None

    def _is_valid_header(self, df):
        """
        Ki·ªÉm tra xem header c√≥ h·ª£p l·ªá kh√¥ng
        """
        if df.empty or len(df.columns) < 2:
            return False

        # T√¨m c√°c t·ª´ kh√≥a quan tr·ªçng trong header
        header_keywords = ['Date', 'Time', 'VoLTE', 'CSSR', 'CDR', 'Traffic',
                           'SRVCC', 'SR', 'HOSR', 'GB', '%', 'Rate']

        header_str = ' '.join([str(col) for col in df.columns])

        # Ki·ªÉm tra c√≥ √≠t nh·∫•t 2 t·ª´ kh√≥a
        keyword_count = sum(1 for keyword in header_keywords if keyword in header_str)

        return keyword_count >= 2

    def clean_dataframe_enhanced(self, df, sheet_name):
        """
        L√†m s·∫°ch dataframe v·ªõi x·ª≠ l√Ω n√¢ng cao v√† chi ti·∫øt h∆°n
        """
        print(f"üßπ L√†m s·∫°ch d·ªØ li·ªáu n√¢ng cao cho {sheet_name}...")
        print(f"   üìä Tr∆∞·ªõc khi l√†m s·∫°ch: {df.shape}")

        if df.empty:
            print("   ‚ùå DataFrame r·ªóng!")
            return None

        # 1. X·ª≠ l√Ω t√™n c·ªôt
        df = self._clean_column_names(df)

        # 2. T√¨m v√† thi·∫øt l·∫≠p header ƒë√∫ng
        df = self._fix_header_row(df, sheet_name)

        if df is None or df.empty:
            return None

        # 3. X√≥a c√°c c·ªôt v√† h√†ng kh√¥ng c·∫ßn thi·∫øt
        df = self._remove_unnecessary_data(df)

        # 4. X·ª≠ l√Ω c·ªôt Date/Time
        df = self._process_datetime_column(df)

        # 5. Chuy·ªÉn ƒë·ªïi c√°c c·ªôt s·ªë
        df = self._convert_numeric_columns(df)

        # 6. L√†m s·∫°ch d·ªØ li·ªáu cu·ªëi c√πng
        df = self._final_cleanup(df)

        if df is None or df.empty:
            print(f"   ‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu h·ª£p l·ªá sau khi l√†m s·∫°ch!")
            return None

        print(f"   ‚ú® Sau khi l√†m s·∫°ch: {df.shape}")
        print(f"   üìã C√°c c·ªôt cu·ªëi c√πng: {list(df.columns[:10])}")

        return df

    def _clean_column_names(self, df):
        """
        L√†m s·∫°ch t√™n c·ªôt
        """
        df.columns = df.columns.astype(str)
        df.columns = [col.strip().replace('\n', ' ').replace('\r', ' ').replace('  ', ' ')
                      for col in df.columns]
        return df

    def _fix_header_row(self, df, sheet_name):
        """
        T√¨m v√† s·ª≠a d√≤ng header ƒë√∫ng
        """
        # T√¨m d√≤ng ch·ª©a t·ª´ kh√≥a quan tr·ªçng
        header_keywords = ['Date', 'Time', 'VoLTE', 'CSSR', 'CDR', 'Traffic', 'SRVCC']

        for i in range(min(5, len(df))):
            row_str = ' '.join([str(val) for val in df.iloc[i].values if pd.notna(val)])
            keyword_count = sum(1 for keyword in header_keywords if keyword in row_str)

            if keyword_count >= 2:  # √çt nh·∫•t 2 t·ª´ kh√≥a
                print(f"   üéØ T√¨m th·∫•y header th·ª±c t·∫ø ·ªü d√≤ng {i}")

                # T·∫°o header m·ªõi
                new_header = []
                for val in df.iloc[i].values:
                    if pd.notna(val) and str(val).strip() != '':
                        new_header.append(str(val).strip())
                    else:
                        new_header.append(f'Col_{len(new_header)}')

                # T·∫°o DataFrame m·ªõi
                data_rows = df.iloc[i + 1:].values
                if len(data_rows) == 0:
                    return None

                # ƒê·∫£m b·∫£o s·ªë c·ªôt kh·ªõp
                min_cols = min(len(new_header), data_rows.shape[1] if len(data_rows) > 0 else 0)
                if min_cols == 0:
                    return None

                new_header = new_header[:min_cols]
                data_rows = data_rows[:, :min_cols]

                df_new = pd.DataFrame(data_rows, columns=new_header)
                return df_new

        return df  # Tr·∫£ v·ªÅ DataFrame g·ªëc n·∫øu kh√¥ng t√¨m th·∫•y header t·ªët h∆°n

    def _remove_unnecessary_data(self, df):
        """
        X√≥a c√°c c·ªôt v√† h√†ng kh√¥ng c·∫ßn thi·∫øt
        """
        # X√≥a c√°c c·ªôt Unnamed
        unnamed_cols = [col for col in df.columns if 'Unnamed' in str(col) or 'Col_' in str(col)]
        if unnamed_cols:
            df = df.drop(columns=unnamed_cols, errors='ignore')
            print(f"   üóëÔ∏è ƒê√£ x√≥a {len(unnamed_cols)} c·ªôt kh√¥ng t√™n")

        # X√≥a c√°c c·ªôt ho√†n to√†n tr·ªëng
        df = df.dropna(axis=1, how='all')

        # X√≥a c√°c h√†ng ho√†n to√†n tr·ªëng
        df = df.dropna(axis=0, how='all')

        # X√≥a c√°c h√†ng c√≥ qu√° √≠t d·ªØ li·ªáu
        threshold = max(2, len(df.columns) * 0.3)  # √çt nh·∫•t 30% c·ªôt c√≥ d·ªØ li·ªáu
        df = df.dropna(thresh=threshold)

        return df.reset_index(drop=True)

    def _process_datetime_column(self, df):
        """
        X·ª≠ l√Ω c·ªôt Date/Time
        """
        if len(df.columns) == 0 or len(df) == 0:
            return df

        # T√¨m c·ªôt Date
        date_col = None
        for col in df.columns[:3]:  # Ki·ªÉm tra 3 c·ªôt ƒë·∫ßu
            col_str = str(col).lower()
            if any(keyword in col_str for keyword in ['date', 'time', 'ng√†y', 'gi·ªù']):
                date_col = col
                break

        if date_col is None:
            date_col = df.columns[0]  # M·∫∑c ƒë·ªãnh c·ªôt ƒë·∫ßu ti√™n

        print(f"   üìÖ X·ª≠ l√Ω c·ªôt th·ªùi gian: {date_col}")

        try:
            # Th·ª≠ c√°c ph∆∞∆°ng ph√°p chuy·ªÉn ƒë·ªïi kh√°c nhau
            original_data = df[date_col].copy()

            # Ph∆∞∆°ng ph√°p 1: Chuy·ªÉn ƒë·ªïi tr·ª±c ti·∫øp
            df[date_col] = pd.to_datetime(df[date_col], errors='coerce')

            # N·∫øu c√≥ qu√° nhi·ªÅu NaT, th·ª≠ ph∆∞∆°ng ph√°p kh√°c
            nat_count = df[date_col].isna().sum()
            if nat_count > len(df) * 0.5:  # H∆°n 50% l√† NaT
                print(f"   ‚ö†Ô∏è Qu√° nhi·ªÅu ng√†y kh√¥ng h·ª£p l·ªá, th·ª≠ ph∆∞∆°ng ph√°p kh√°c...")

                # Ph∆∞∆°ng ph√°p 2: X·ª≠ l√Ω s·ªë Excel
                try:
                    df[date_col] = pd.to_datetime(original_data, origin='1899-12-30', unit='D', errors='coerce')
                    nat_count = df[date_col].isna().sum()
                except:
                    pass

                # Ph∆∞∆°ng ph√°p 3: Parsing linh ho·∫°t
                if nat_count > len(df) * 0.5:
                    try:
                        df[date_col] = pd.to_datetime(original_data, infer_datetime_format=True, errors='coerce')
                    except:
                        pass

            # Lo·∫°i b·ªè c√°c h√†ng c√≥ ng√†y kh√¥ng h·ª£p l·ªá
            valid_dates = df[date_col].notna()
            df = df[valid_dates].reset_index(drop=True)

            # S·∫Øp x·∫øp theo ng√†y
            if len(df) > 0:
                df = df.sort_values(by=date_col).reset_index(drop=True)
                print(f"   ‚úÖ ƒê√£ chuy·ªÉn ƒë·ªïi {len(df)} ng√†y h·ª£p l·ªá")

        except Exception as e:
            print(f"   ‚ö†Ô∏è L·ªói x·ª≠ l√Ω ng√†y th√°ng: {e}")

        return df

    def _convert_numeric_columns(self, df):
        """
        Chuy·ªÉn ƒë·ªïi c√°c c·ªôt s·ªë
        """
        numeric_converted = 0

        # B·ªè qua c·ªôt ƒë·∫ßu ti√™n (Date/Time)
        for col in df.columns[1:]:
            try:
                original_count = df[col].count()

                # X·ª≠ l√Ω c√°c k√Ω t·ª± ƒë·∫∑c bi·ªát trong s·ªë
                if df[col].dtype == 'object':
                    df[col] = df[col].astype(str).str.replace(',', '').str.replace('%', '').str.replace(' ', '')
                    df[col] = df[col].replace(['', 'nan', 'NaN', 'null', 'NULL', '-'], np.nan)

                # Chuy·ªÉn ƒë·ªïi sang s·ªë
                df[col] = pd.to_numeric(df[col], errors='coerce')

                new_count = df[col].count()

                if new_count > 0:
                    numeric_converted += 1
                    if new_count < original_count:
                        lost_pct = (original_count - new_count) / original_count * 100
                        if lost_pct > 20:  # C·∫£nh b√°o n·∫øu m·∫•t qu√° 20% d·ªØ li·ªáu
                            print(f"   ‚ö†Ô∏è {col}: m·∫•t {lost_pct:.1f}% d·ªØ li·ªáu ({original_count} -> {new_count})")

            except Exception as e:
                print(f"   ‚ö†Ô∏è L·ªói chuy·ªÉn ƒë·ªïi c·ªôt {col}: {e}")
                continue

        print(f"   üî¢ ƒê√£ chuy·ªÉn ƒë·ªïi {numeric_converted} c·ªôt sang ki·ªÉu s·ªë")
        return df

    def _final_cleanup(self, df):
        """
        L√†m s·∫°ch cu·ªëi c√πng
        """
        # X√≥a c√°c h√†ng c√≥ qu√° √≠t d·ªØ li·ªáu
        min_valid_cols = max(2, len(df.columns) * 0.4)  # √çt nh·∫•t 40% c·ªôt c√≥ d·ªØ li·ªáu
        df = df.dropna(thresh=min_valid_cols)

        # X√≥a c√°c c·ªôt c√≥ qu√° √≠t d·ªØ li·ªáu
        min_valid_rows = max(1, len(df) * 0.1)  # √çt nh·∫•t 10% h√†ng c√≥ d·ªØ li·ªáu
        df = df.dropna(axis=1, thresh=min_valid_rows)

        return df.reset_index(drop=True)

    def save_to_csv(self, dataframes, output_dir="output_charts"):
        """
        L∆∞u c√°c DataFrame th√†nh file CSV
        """
        print(f"\nüíæ L∆∞u d·ªØ li·ªáu th√†nh CSV...")
        os.makedirs(output_dir, exist_ok=True)

        for sheet_name, df in dataframes.items():
            # T·∫°o t√™n file CSV
            if 'Daily' in sheet_name or 'daily' in sheet_name.lower():
                csv_filename = 'Net_KPI_Daily.csv'
            elif 'Hourly' in sheet_name or 'hourly' in sheet_name.lower() or 'hour' in sheet_name.lower():
                csv_filename = 'Net_KPI_Hourly.csv'
            else:
                safe_name = "".join(c for c in sheet_name if c.isalnum() or c in (' ', '-', '_')).replace(' ', '_')
                csv_filename = f'{safe_name}.csv'

            csv_path = os.path.join(output_dir, csv_filename)

            try:
                df.to_csv(csv_path, index=False, encoding='utf-8-sig')
                print(f"‚úÖ ƒê√£ l∆∞u: {csv_filename} ({df.shape[0]} h√†ng √ó {df.shape[1]} c·ªôt)")

                # L∆∞u th√¥ng tin ƒë·ªÉ t·∫°o bi·ªÉu ƒë·ªì sau
                self.csv_files[sheet_name] = csv_path
                self.cleaned_data[sheet_name] = df

            except Exception as e:
                print(f"‚ùå L·ªói khi l∆∞u {csv_filename}: {e}")

        return self.csv_files

    def create_charts_from_csv(self, output_dir="output_charts"):
        """
        T·∫°o bi·ªÉu ƒë·ªì t·ª´ c√°c file CSV
        """
        print(f"\nüé® T·∫°o bi·ªÉu ƒë·ªì t·ª´ d·ªØ li·ªáu CSV...")

        for sheet_name, csv_path in self.csv_files.items():
            # X√°c ƒë·ªãnh lo·∫°i bi·ªÉu ƒë·ªì
            if 'Daily' in sheet_name or 'daily' in sheet_name.lower():
                chart_folder = os.path.join(output_dir, "Chart_daily")
                data_type = "Daily"
            elif 'Hourly' in sheet_name or 'hourly' in sheet_name.lower():
                chart_folder = os.path.join(output_dir, "Chart_hourly")
                data_type = "Hourly"
            else:
                chart_folder = os.path.join(output_dir, "Charts")
                data_type = "General"

            # T·∫°o bi·ªÉu ƒë·ªì
            self._generate_charts_for_data(csv_path, chart_folder, data_type)

    def _generate_charts_for_data(self, csv_file, chart_folder, data_type):
        """
        T·∫°o bi·ªÉu ƒë·ªì cho m·ªôt file CSV c·ª• th·ªÉ
        """
        print(f"\nüìä T·∫°o bi·ªÉu ƒë·ªì {data_type}...")

        if not os.path.exists(csv_file):
            print(f"   ‚ùå Kh√¥ng t√¨m th·∫•y file: {csv_file}")
            return

        os.makedirs(chart_folder, exist_ok=True)

        try:
            # ƒê·ªçc d·ªØ li·ªáu
            df = pd.read_csv(csv_file)
            print(f"   üìä ƒê·ªçc d·ªØ li·ªáu: {df.shape}")

            if df.empty or len(df.columns) < 2:
                print(f"   ‚ö†Ô∏è D·ªØ li·ªáu kh√¥ng ƒë·ªß ƒë·ªÉ t·∫°o bi·ªÉu ƒë·ªì")
                return

            # C·ªôt th·ªùi gian (c·ªôt ƒë·∫ßu ti√™n)
            x_column = df.columns[0]
            print(f"   üìÖ C·ªôt th·ªùi gian: {x_column}")

            # Chuy·ªÉn ƒë·ªïi c·ªôt th·ªùi gian
            try:
                df[x_column] = pd.to_datetime(df[x_column])
            except:
                print(f"   ‚ö†Ô∏è Kh√¥ng th·ªÉ chuy·ªÉn ƒë·ªïi c·ªôt th·ªùi gian")

            # L·ªçc c√°c c·ªôt s·ªë h·ª£p l·ªá
            numeric_columns = []
            for col in df.columns[1:]:
                if pd.api.types.is_numeric_dtype(df[col]) and df[col].count() > 0:
                    # Ki·ªÉm tra c√≥ ƒë·ªß d·ªØ li·ªáu kh√¥ng (√≠t nh·∫•t 20% kh√¥ng ph·∫£i NaN)
                    valid_ratio = df[col].count() / len(df)
                    if valid_ratio >= 0.2:
                        numeric_columns.append(col)

            print(f"   üìà T√¨m th·∫•y {len(numeric_columns)} c·ªôt d·ªØ li·ªáu h·ª£p l·ªá")

            if not numeric_columns:
                print(f"   ‚ùå Kh√¥ng c√≥ c·ªôt d·ªØ li·ªáu h·ª£p l·ªá!")
                return

            chart_count = 0

            # 1. T·∫°o bi·ªÉu ƒë·ªì ƒë∆∞·ªùng cho t·ª´ng KPI
            print(f"   üìä T·∫°o bi·ªÉu ƒë·ªì ƒë∆∞·ªùng ri√™ng l·∫ª...")
            for col_name in numeric_columns:
                try:
                    chart_path = self._create_line_chart(df, x_column, col_name, chart_folder)
                    if chart_path:
                        chart_count += 1
                except Exception as e:
                    print(f"   ‚ùå L·ªói t·∫°o bi·ªÉu ƒë·ªì ƒë∆∞·ªùng {col_name}: {e}")

            # 2. T·∫°o bi·ªÉu ƒë·ªì k·∫øt h·ª£p (ƒë∆∞·ªùng + c·ªôt)
            print(f"   üìä T·∫°o bi·ªÉu ƒë·ªì k·∫øt h·ª£p...")
            for i in range(0, len(numeric_columns) - 1, 2):
                try:
                    col1 = numeric_columns[i]
                    col2 = numeric_columns[i + 1] if i + 1 < len(numeric_columns) else None

                    if col2 and col1 != col2:
                        chart_path = self._create_combo_chart(df, x_column, col1, col2, chart_folder)
                        if chart_path:
                            chart_count += 1
                except Exception as e:
                    print(f"   ‚ùå L·ªói t·∫°o bi·ªÉu ƒë·ªì k·∫øt h·ª£p: {e}")

            print(f"   üéâ ƒê√£ t·∫°o {chart_count} bi·ªÉu ƒë·ªì cho {data_type}")

        except Exception as e:
            print(f"   ‚ùå L·ªói t·∫°o bi·ªÉu ƒë·ªì {data_type}: {e}")

    def _create_line_chart(self, df, x_col, y_col, chart_folder):
        """
        T·∫°o bi·ªÉu ƒë·ªì ƒë∆∞·ªùng cho m·ªôt KPI
        """
        try:
            plt.figure(figsize=(12, 6))

            # L·ªçc d·ªØ li·ªáu h·ª£p l·ªá
            clean_data = df[[x_col, y_col]].dropna()
            if clean_data.empty:
                plt.close()
                return None

            # V·∫Ω bi·ªÉu ƒë·ªì
            plt.plot(clean_data[x_col], clean_data[y_col],
                     marker='o', linewidth=2.5, markersize=4,
                     color='#1f77b4', alpha=0.8, label=y_col)

            # ƒê·ªãnh d·∫°ng bi·ªÉu ƒë·ªì
            plt.title(f'{y_col} Trend Analysis', fontsize=14, fontweight='bold', pad=20)
            plt.xlabel('Date/Time', fontsize=12)
            plt.ylabel(y_col, fontsize=12)
            plt.grid(True, alpha=0.3, linestyle='--')
            plt.legend(fontsize=11, loc='best')

            # ƒê·ªãnh d·∫°ng tr·ª•c x cho datetime
            if pd.api.types.is_datetime64_any_dtype(clean_data[x_col]):
                plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%m/%d'))
                plt.gca().xaxis.set_major_locator(mdates.DayLocator(interval=max(1, len(clean_data) // 10)))

            plt.xticks(rotation=45, fontsize=10)
            plt.yticks(fontsize=10)

            # M√†u n·ªÅn
            plt.gca().set_facecolor('#f8f9fa')

            plt.tight_layout()

            # L∆∞u bi·ªÉu ƒë·ªì
            safe_filename = "".join(c for c in y_col if c.isalnum() or c in (' ', '-', '_')).replace(' ', '_')
            chart_path = os.path.join(chart_folder, f"{safe_filename}_line.png")
            plt.savefig(chart_path, dpi=300, bbox_inches='tight', facecolor='white')
            plt.close()

            return chart_path

        except Exception as e:
            plt.close()
            return None

    def _create_combo_chart(self, df, x_col, y_line, y_bar, chart_folder):
        """
        T·∫°o bi·ªÉu ƒë·ªì k·∫øt h·ª£p ƒë∆∞·ªùng v√† c·ªôt
        """
        try:
            # L·ªçc d·ªØ li·ªáu h·ª£p l·ªá
            clean_data = df[[x_col, y_line, y_bar]].dropna()
            if clean_data.empty:
                return None

            fig, ax1 = plt.subplots(figsize=(12, 6))

            # Tr·ª•c Y b√™n tr√°i (ƒë∆∞·ªùng)
            color_line = '#1f77b4'
            ax1.set_xlabel('Date/Time', fontsize=12)
            ax1.set_ylabel(y_line, color=color_line, fontsize=12, fontweight='bold')
            ax1.plot(clean_data[x_col], clean_data[y_line],
                     marker='o', color=color_line, linewidth=2.5, markersize=4,
                     label=y_line, alpha=0.8)
            ax1.tick_params(axis='y', labelcolor=color_line, labelsize=10)
            ax1.tick_params(axis='x', labelsize=10)
            ax1.grid(True, alpha=0.3, linestyle='--')

            # Tr·ª•c Y b√™n ph·∫£i (c·ªôt)
            ax2 = ax1.twinx()
            color_bar = '#ff7f0e'
            ax2.set_ylabel(y_bar, color=color_bar, fontsize=12, fontweight='bold')

            # T√≠nh ƒë·ªô r·ªông c·ªôt
            bar_width = 0.6 if len(clean_data) > 15 else 0.8

            ax2.bar(clean_data[x_col], clean_data[y_bar],
                    alpha=0.6, color=color_bar, label=y_bar, width=bar_width)
            ax2.tick_params(axis='y', labelcolor=color_bar, labelsize=10)

            # Ti√™u ƒë·ªÅ
            plt.title(f'{y_line} & {y_bar} Combined Analysis',
                      fontsize=14, fontweight='bold', pad=20)

            # ƒê·ªãnh d·∫°ng tr·ª•c x
            if pd.api.types.is_datetime64_any_dtype(clean_data[x_col]):
                fig.autofmt_xdate()
                ax1.xaxis.set_major_formatter(mdates.DateFormatter('%m/%d'))
            else:
                plt.xticks(rotation=45)

            # Legend k·∫øt h·ª£p
            lines1, labels1 = ax1.get_legend_handles_labels()
            lines2, labels2 = ax2.get_legend_handles_labels()
            ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper left', fontsize=10)

            # M√†u n·ªÅn
            ax1.set_facecolor('#f8f9fa')

            fig.tight_layout()

            # L∆∞u bi·ªÉu ƒë·ªì
            safe_filename1 = "".join(c for c in y_line if c.isalnum() or c in (' ', '-', '_')).replace(' ', '_')
            safe_filename2 = "".join(c for c in y_bar if c.isalnum() or c in (' ', '-', '_')).replace(' ', '_')
            chart_path = os.path.join(chart_folder, f"{safe_filename1}_and_{safe_filename2}_combo.png")
            plt.savefig(chart_path, dpi=300, bbox_inches='tight', facecolor='white')
            plt.close()

            return chart_path

        except Exception as e:
            plt.close()
            return None

    def create_comprehensive_report(self, output_dir="output_charts"):
        """
        T·∫°o b√°o c√°o t·ªïng h·ª£p CH√çNH - kh√¥ng c√≥ dashboard, ch·ªâ bi·ªÉu ƒë·ªì
        """
        print(f"\nüìã T·∫°o b√°o c√°o t·ªïng h·ª£p ch·ªâ bi·ªÉu ƒë·ªì...")

        try:
            # Thu th·∫≠p t·∫•t c·∫£ file ·∫£nh bi·ªÉu ƒë·ªì (kh√¥ng bao g·ªìm dashboard)
            image_files = []

            # Bi·ªÉu ƒë·ªì Daily
            daily_chart_dir = os.path.join(output_dir, "Chart_daily")
            if os.path.exists(daily_chart_dir):
                for file in sorted(os.listdir(daily_chart_dir)):
                    if file.endswith('.png'):
                        image_files.append(os.path.join(daily_chart_dir, file))

            # Bi·ªÉu ƒë·ªì Hourly
            hourly_chart_dir = os.path.join(output_dir, "Chart_hourly")
            if os.path.exists(hourly_chart_dir):
                for file in sorted(os.listdir(hourly_chart_dir)):
                    if file.endswith('.png'):
                        image_files.append(os.path.join(hourly_chart_dir, file))

            if not image_files:
                print("   ‚ùå Kh√¥ng t√¨m th·∫•y file ·∫£nh n√†o ƒë·ªÉ t·∫°o b√°o c√°o")
                return None

            print(f"   üìä T√¨m th·∫•y {len(image_files)} bi·ªÉu ƒë·ªì")

            # T·∫°o b√°o c√°o t·ªïng h·ª£p 1 trang duy nh·∫•t
            report_path = self._create_single_page_report(image_files, output_dir)

            if report_path:
                print(f"‚úÖ ƒê√£ t·∫°o b√°o c√°o t·ªïng h·ª£p: {report_path}")

                # T·∫°o PDF t·ª´ PNG
                try:
                    pdf_path = report_path.replace('.png', '.pdf')
                    img = Image.open(report_path)
                    img.save(pdf_path, "PDF", quality=95)
                    print(f"‚úÖ ƒê√£ t·∫°o b√°o c√°o PDF: {pdf_path}")
                except Exception as e:
                    print(f"‚ö†Ô∏è Kh√¥ng th·ªÉ t·∫°o PDF: {e}")

            return report_path

        except Exception as e:
            print(f"‚ùå L·ªói t·∫°o b√°o c√°o t·ªïng h·ª£p: {e}")
            return None

    def _create_single_page_report(self, image_files, output_dir):
        """
        T·∫°o b√°o c√°o 1 trang duy nh·∫•t v·ªõi layout t·ªëi ∆∞u
        """
        try:
            if not image_files:
                return None

            # ƒê·ªçc t·∫•t c·∫£ ·∫£nh
            images = []
            for img_path in image_files:
                try:
                    img = Image.open(img_path)
                    images.append((img, os.path.basename(img_path)))
                except Exception as e:
                    print(f"   ‚ö†Ô∏è Kh√¥ng th·ªÉ ƒë·ªçc {img_path}: {e}")

            if not images:
                return None

            # C·∫•u h√¨nh layout cho 1 trang A4 (t·ªâ l·ªá 210:297)
            page_width = 2100  # pixels (ƒë·ªô ph√¢n gi·∫£i cao)
            page_height = 2970  # pixels (t·ªâ l·ªá A4)

            # C·∫•u h√¨nh layout
            margin = 60
            header_height = 120
            spacing = 40

            # T√≠nh to√°n s·ªë bi·ªÉu ƒë·ªì tr√™n m·ªói h√†ng v√† c·ªôt ƒë·ªÉ v·ª´a 1 trang
            total_charts = len(images)

            if total_charts <= 2:
                cols, rows = 1, total_charts
            elif total_charts <= 4:
                cols, rows = 2, 2
            elif total_charts <= 6:
                cols, rows = 2, 3
            elif total_charts <= 9:
                cols, rows = 3, 3
            else:
                # N·∫øu qu√° nhi·ªÅu bi·ªÉu ƒë·ªì, ch·ªâ l·∫•y 9 bi·ªÉu ƒë·ªì ƒë·∫ßu ti√™n
                cols, rows = 3, 3
                images = images[:9]
                total_charts = 9
                print(f"   ‚ö†Ô∏è Qu√° nhi·ªÅu bi·ªÉu ƒë·ªì, ch·ªâ hi·ªÉn th·ªã {total_charts} bi·ªÉu ƒë·ªì ƒë·∫ßu ti√™n")

            # T√≠nh k√≠ch th∆∞·ªõc bi·ªÉu ƒë·ªì
            available_width = page_width - 2 * margin - (cols - 1) * spacing
            available_height = page_height - header_height - 2 * margin - (rows - 1) * spacing

            chart_width = available_width // cols
            chart_height = available_height // rows

            # T·∫°o canvas
            report_img = Image.new('RGB', (page_width, page_height), 'white')
            draw = ImageDraw.Draw(report_img)

            # Header
            try:
                title_font = ImageFont.truetype("arial.ttf", 48)
                subtitle_font = ImageFont.truetype("arial.ttf", 24)
            except:
                title_font = ImageFont.load_default()
                subtitle_font = ImageFont.load_default()

            # Ti√™u ƒë·ªÅ ch√≠nh
            title = "VoLTE KPI ANALYSIS REPORT"
            title_bbox = draw.textbbox((0, 0), title, font=title_font)
            title_width = title_bbox[2] - title_bbox[0]
            draw.text(((page_width - title_width) // 2, margin), title,
                      fill='navy', font=title_font)

            # Ph·ª• ƒë·ªÅ
            subtitle = f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M')} | Charts: {total_charts}"
            subtitle_bbox = draw.textbbox((0, 0), subtitle, font=subtitle_font)
            subtitle_width = subtitle_bbox[2] - subtitle_bbox[0]
            draw.text(((page_width - subtitle_width) // 2, margin + 60), subtitle,
                      fill='gray', font=subtitle_font)

            # V·∫Ω ƒë∆∞·ªùng ph√¢n c√°ch
            line_y = header_height + margin - 10
            draw.line([(margin, line_y), (page_width - margin, line_y)], fill='lightgray', width=2)

            # V·∫Ω c√°c bi·ªÉu ƒë·ªì
            start_y = header_height + margin + 20

            for i, (chart_img, filename) in enumerate(images):
                row = i // cols
                col = i % cols

                x = margin + col * (chart_width + spacing)
                y = start_y + row * (chart_height + spacing)

                # Resize bi·ªÉu ƒë·ªì gi·ªØ nguy√™n t·ªâ l·ªá
                chart_resized = self._resize_image_proportional(chart_img, chart_width, chart_height)

                # CƒÉn gi·ªØa bi·ªÉu ƒë·ªì trong √¥
                chart_w, chart_h = chart_resized.size
                center_x = x + (chart_width - chart_w) // 2
                center_y = y + (chart_height - chart_h) // 2

                report_img.paste(chart_resized, (center_x, center_y))

                # Th√™m border nh·∫π quanh bi·ªÉu ƒë·ªì
                border_rect = [center_x - 2, center_y - 2,
                               center_x + chart_w + 2, center_y + chart_h + 2]
                draw.rectangle(border_rect, outline='lightgray', width=1)

            # Footer
            footer_text = f"Total KPIs Analyzed: {total_charts} | Report Format: Single Page Summary"
            footer_bbox = draw.textbbox((0, 0), footer_text, font=subtitle_font)
            footer_width = footer_bbox[2] - footer_bbox[0]
            draw.text(((page_width - footer_width) // 2, page_height - 60), footer_text,
                      fill='gray', font=subtitle_font)

            # L∆∞u b√°o c√°o
            report_path = os.path.join(output_dir, "VoLTE_KPI_Single_Page_Report.png")
            report_img.save(report_path, "PNG", quality=95, dpi=(300, 300))

            return report_path

        except Exception as e:
            print(f"‚ùå L·ªói t·∫°o b√°o c√°o 1 trang: {e}")
            return None

    def _resize_image_proportional(self, img, max_width, max_height):
        """
        Resize ·∫£nh gi·ªØ nguy√™n t·ªâ l·ªá v√† fit v√†o k√≠ch th∆∞·ªõc cho ph√©p
        """
        original_width, original_height = img.size

        # T√≠nh t·ªâ l·ªá resize
        ratio_w = max_width / original_width
        ratio_h = max_height / original_height
        ratio = min(ratio_w, ratio_h)  # Ch·ªçn t·ªâ l·ªá nh·ªè h∆°n ƒë·ªÉ ƒë·∫£m b·∫£o fit

        # T√≠nh k√≠ch th∆∞·ªõc m·ªõi
        new_width = int(original_width * ratio)
        new_height = int(original_height * ratio)

        return img.resize((new_width, new_height), Image.Resampling.LANCZOS)

    def process_complete_workflow(self, excel_path, output_dir="output_charts"):
        """
        Th·ª±c hi·ªán quy tr√¨nh ho√†n ch·ªânh t·ª´ Excel ƒë·∫øn b√°o c√°o (KH√îNG c√≥ dashboard)
        """
        print(f"\nüéØ B·∫ÆT ƒê·∫¶U QUY TR√åNH X·ª¨ L√ù HO√ÄN CH·ªàNH")
        print(f"üìÅ File ƒë·∫ßu v√†o: {excel_path}")
        print(f"üìÅ Th∆∞ m·ª•c ƒë·∫ßu ra: {output_dir}")
        print("=" * 70)

        # B∆∞·ªõc 1: ƒê·ªçc Excel
        print("\nüìñ B∆Ø·ªöC 1: ƒê·ªåC V√Ä PH√ÇN T√çCH FILE EXCEL")
        dataframes = self.read_excel_file(excel_path)

        if not dataframes:
            print("‚ùå Kh√¥ng th·ªÉ ƒë·ªçc file Excel!")
            return False

        # B∆∞·ªõc 2: L√†m s·∫°ch d·ªØ li·ªáu
        print("\nüßπ B∆Ø·ªöC 2: L√ÄM S·∫†CH D·ªÆ LI·ªÜU")
        cleaned_dataframes = {}

        for sheet_name, df in dataframes.items():
            cleaned_df = self.clean_dataframe_enhanced(df, sheet_name)
            if cleaned_df is not None and not cleaned_df.empty:
                cleaned_dataframes[sheet_name] = cleaned_df
            else:
                print(f"‚ùå Kh√¥ng th·ªÉ l√†m s·∫°ch d·ªØ li·ªáu t·ª´ {sheet_name}")

        if not cleaned_dataframes:
            print("‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu h·ª£p l·ªá sau khi l√†m s·∫°ch!")
            return False

        # B∆∞·ªõc 3: L∆∞u CSV
        print("\nüíæ B∆Ø·ªöC 3: L∆ØU D·ªÆ LI·ªÜU TH√ÄNH CSV")
        csv_files = self.save_to_csv(cleaned_dataframes, output_dir)

        if not csv_files:
            print("‚ùå Kh√¥ng th·ªÉ l∆∞u file CSV!")
            return False

        # B∆∞·ªõc 4: T·∫°o bi·ªÉu ƒë·ªì
        print("\nüé® B∆Ø·ªöC 4: T·∫†O BI·ªÇU ƒê·ªí")
        self.create_charts_from_csv(output_dir)

        # B∆∞·ªõc 5: T·∫°o b√°o c√°o t·ªïng h·ª£p (KH√îNG c√≥ dashboard)
        print("\nüìã B∆Ø·ªöC 5: T·∫†O B√ÅO C√ÅO T·ªîNG H·ª¢P")
        report_path = self.create_comprehensive_report(output_dir)

        # T·ªïng k·∫øt
        print("\n" + "=" * 70)
        print("üéâ HO√ÄN T·∫§T QUY TR√åNH X·ª¨ L√ù!")
        print("=" * 70)
        print(f"üìÅ K·∫øt qu·∫£ l∆∞u t·∫°i: {output_dir}")
        print("\nüìä C·∫•u tr√∫c k·∫øt qu·∫£:")
        print("üìÇ output_charts/")

        for sheet_name, csv_path in csv_files.items():
            print(f"   üìÑ {os.path.basename(csv_path)}")

        chart_folders = ['Chart_daily', 'Chart_hourly']
        for folder in chart_folders:
            folder_path = os.path.join(output_dir, folder)
            if os.path.exists(folder_path):
                chart_count = len([f for f in os.listdir(folder_path) if f.endswith('.png')])
                print(f"   üìÇ {folder}/ ({chart_count} bi·ªÉu ƒë·ªì)")

        if report_path and os.path.exists(report_path):
            print(f"   üìä VoLTE_KPI_Single_Page_Report.png")

        pdf_path = os.path.join(output_dir, "VoLTE_KPI_Single_Page_Report.pdf")
        if os.path.exists(pdf_path):
            print(f"   üìä VoLTE_KPI_Single_Page_Report.pdf")

        print("=" * 70)
        return True


def main():
    """
    H√†m main ƒë·ªÉ ch·∫°y ch∆∞∆°ng tr√¨nh
    """
    print("üöÄ VOLTE KPI DATA PROCESSING SYSTEM")
    print("=" * 70)
    print("üìã Ch·ª©c nƒÉng:")
    print("   ‚úÖ Chuy·ªÉn ƒë·ªïi Excel sang CSV (ch·ªâ 2 sheet: Net KPI_Daily, Net KPI_Hourly)")
    print("   ‚úÖ L√†m s·∫°ch d·ªØ li·ªáu chuy√™n s√¢u")
    print("   ‚úÖ T·∫°o bi·ªÉu ƒë·ªì ƒë∆∞·ªùng v√† bi·ªÉu ƒë·ªì k·∫øt h·ª£p")
    print("   ‚úÖ T·∫°o b√°o c√°o t·ªïng h·ª£p 1 trang PNG/PDF (KH√îNG c√≥ dashboard)")
    print("=" * 70)

    # Kh·ªüi t·∫°o processor
    processor = VoLTEKPIProcessor()

    # ƒê∆∞·ªùng d·∫´n file Excel (thay ƒë·ªïi theo file th·ª±c t·∫ø c·ªßa b·∫°n)
    excel_file = "4G_KPI Cell VoLTE_20250807.xlsx"

    # Ki·ªÉm tra file t·ªìn t·∫°i
    if not os.path.exists(excel_file):
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y file: {excel_file}")
        print("üí° H√£y ƒë·∫£m b·∫£o file Excel ·ªü c√πng th∆∞ m·ª•c v·ªõi script n√†y")
        print("üí° Ho·∫∑c thay ƒë·ªïi ƒë∆∞·ªùng d·∫´n trong bi·∫øn excel_file")
        return

    # Ch·∫°y quy tr√¨nh ho√†n ch·ªânh
    success = processor.process_complete_workflow(excel_file)

    if success:
        print("\nüéä TH√ÄNH C√îNG! H√£y ki·ªÉm tra th∆∞ m·ª•c 'output_charts'")
        print("üìä B√°o c√°o t·ªïng h·ª£p ƒë∆∞·ª£c l∆∞u d·∫°ng PNG v√† PDF 1 trang duy nh·∫•t")
    else:
        print("\n‚ùå C√ì L·ªñI X·∫¢Y RA! Vui l√≤ng ki·ªÉm tra l·∫°i d·ªØ li·ªáu ƒë·∫ßu v√†o")


# Utility function ƒë·ªÉ fix file CSV b·ªã l·ªói (n·∫øu c·∫ßn)
def fix_csv_file(input_csv, output_csv):
    """
    H√†m ti·ªán √≠ch ƒë·ªÉ s·ª≠a file CSV b·ªã l·ªói
    """
    processor = VoLTEKPIProcessor()

    try:
        print(f"üîß ƒêang s·ª≠a file CSV: {input_csv}")

        # ƒê·ªçc file v·ªõi header=None
        df = pd.read_csv(input_csv, header=None)

        # S·ª≠ d·ª•ng h√†m l√†m s·∫°ch c·ªßa processor
        df_cleaned = processor.clean_dataframe_enhanced(df, "CSV_Fix")

        if df_cleaned is not None:
            df_cleaned.to_csv(output_csv, index=False, encoding='utf-8-sig')
            print(f"‚úÖ ƒê√£ s·ª≠a v√† l∆∞u: {output_csv}")
            return True
        else:
            print("‚ùå Kh√¥ng th·ªÉ s·ª≠a file CSV")
            return False

    except Exception as e:
        print(f"‚ùå L·ªói khi s·ª≠a file: {e}")
        return False


if __name__ == "__main__":
    # Ki·ªÉm tra c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt
    required_packages = {
        'pandas': 'pandas',
        'matplotlib': 'matplotlib',
        'numpy': 'numpy',
        'PIL': 'Pillow',
        'openpyxl': 'openpyxl'
    }

    print("üì¶ Ki·ªÉm tra th∆∞ vi·ªán c·∫ßn thi·∫øt:")
    missing_packages = []

    for package, install_name in required_packages.items():
        try:
            __import__(package)
            print(f"   ‚úÖ {package}")
        except ImportError:
            print(f"   ‚ùå {package} - C·∫ßn c√†i ƒë·∫∑t: pip install {install_name}")
            missing_packages.append(install_name)

    if missing_packages:
        print(f"\n‚ö†Ô∏è Vui l√≤ng c√†i ƒë·∫∑t c√°c package c√≤n thi·∫øu:")
        print(f"pip install {' '.join(missing_packages)}")
        exit()

    print("\n")

    # Ch·∫°y ch∆∞∆°ng tr√¨nh ch√≠nh
    main()